[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Reproducible Road Safety Research with R",
    "section": "",
    "text": "Preamble",
    "crumbs": [
      "Preamble"
    ]
  },
  {
    "objectID": "index.html#about-the-author",
    "href": "index.html#about-the-author",
    "title": "Reproducible Road Safety Research with R",
    "section": "About the Author",
    "text": "About the Author\nRobin Lovelace is Professor of Transport Data Science at the Leeds Institute for Transport Studies (ITS) specialising in the analysis of regional transport systems and modelling scenarios of change. Robin is Lead Developer of the Propensity to Cycle Tool (see www.pct.bike) and follow-on projects such as the Network Planning Tool for Scotland (NPT), Principal Investigator of the Department for Transport funded SaferActive project and author of popular open source software packages (such as stplanr) and books (such as Geocomputation with R).",
    "crumbs": [
      "Preamble"
    ]
  },
  {
    "objectID": "index.html#disclaimer",
    "href": "index.html#disclaimer",
    "title": "Reproducible Road Safety Research with R",
    "section": "Disclaimer",
    "text": "Disclaimer\nThis report has been prepared for the RAC Foundation by Robin Lovelace at the Leeds Institute for Transport Studies. Any errors or omissions are the author’s sole responsibility. The report content reflects the views of the author and not necessarily those of the RAC Foundation.",
    "crumbs": [
      "Preamble"
    ]
  },
  {
    "objectID": "index.html#foreword-road-safety-gb",
    "href": "index.html#foreword-road-safety-gb",
    "title": "Reproducible Road Safety Research with R",
    "section": "Foreword: Road Safety GB",
    "text": "Foreword: Road Safety GB\nRoad Safety GB recognises the importance of high quality data analysis as a fundamental element in efforts to reduce road casualties at a local and national level by enabling evidence-based intervention. The use of open source software like R in this way is to be actively encouraged and tools such as this manual provide valuable support for analysts working across the industry in enhancing the analysis they are able to provide to decision-makers. This approach also supports the reproduction of high-quality analysis up and down the country using locally-held data, which I hope in turn will improve the consistency and quality of evidence used in day-to-day road safety activity.\nI would like to thank those that have worked hard to pull this manual together and encourage all those working with road safety data to make use of this resource to learn, develop and share their analysis methods with others.\nMatt Staton, Director of Research, Road Safety GB",
    "crumbs": [
      "Preamble"
    ]
  },
  {
    "objectID": "index.html#foreword-department-for-transport",
    "href": "index.html#foreword-department-for-transport",
    "title": "Reproducible Road Safety Research with R",
    "section": "Foreword: Department for Transport",
    "text": "Foreword: Department for Transport\nThe STATS19 data collection for road traffic collisions has existed in the current form since 1979. It is a well-established source of road safety data which offers great insights into the trends and locations of road traffic collisions for central and local government, the police and the general public. The openness and accessibility of this data is important to DfT, who have launched a data download tool to improve the access to road safety data. As well as working to enhance the use of R and Reproducible Analytical Pipelines to improve the quality of their analysis and publications.\nThe standard use of packages and code creates transparent and consistent framework for analysis. And the work by the University of Leeds takes new and experienced R users through the process of producing temporal and special analysis using STATS19 data. We commend this book to all those who wish to conduct analysis of road traffic collisions and use analysis to help save lives on our roads.\nJohn Wilkins, Deputy Director, Statistics Travel and Safety Division, Department for Transport",
    "crumbs": [
      "Preamble"
    ]
  },
  {
    "objectID": "index.html#foreword-rac-foundation",
    "href": "index.html#foreword-rac-foundation",
    "title": "Reproducible Road Safety Research with R",
    "section": "Foreword: RAC Foundation",
    "text": "Foreword: RAC Foundation\nIf there is one thing to notice from the changes in the road safety sector over the past decade it is the rapid development of data and data science. Not too long ago road safety analysis involved mounds of paperwork, file sizes too large for transmission, and geo-coding using old A to Zs. We now have systems with handheld devices taking precise GPS co-ordinates at the scene, online-only systems and automated error checking. The volumes of data we possess are growing rapidly, our abilities to maintain and clean data have become more straightforward and what it is possible to discover from data has become cheaper and easier to obtain. Our expectation is, understandably, that across the sector we should be able to access road safety data and to do more with it, more easily and more readily.\nThe types of analyses that we used to associate with sectors like pharmaceuticals and insurance, with high-end technology and well-funded research programmes, are increasingly within the grasp of people with normal laptops and pay-by-the-hour cloud-computing, and in sectors that don’t always have much money to throw at a problem. The good news is that there is scope for road safety analysis to pick up these methods and approaches adopted in other sectors and work hopefully to bring about the new insights we need to improve road safety.\nAt the RAC Foundation we want road transport to benefit from this new world of data analysis – where the tools available are getting cheaper and what is possible is growing rapidly. But this can only happen if the opportunities are given to the sector’s road safety analysts to learn new skills for the job.\nWhile Great Britain has a history of road crash data recording that is world-leading, our analysis of it is all-too-often locked in to a pattern of labour-intensive and repetitious reporting, with analysts lacking the support they need to improve skills and find the space to do the sorts of analyses that will help us achieve the next step-change decline in casualties on our roads. Which is why we commissioned this work from Robin Lovelace.\nWe hope that Robin’s manual will go some way towards meeting the current need: by giving road safety analysts a self-help training manual to develop their skills in R,, the open-source analytical tool. This manual covers everything one would need for doing the regular tasks of road safety analysis entirely in the R language, designed to be accessible to the newcomer. R allows you to code analysis for reproducible research; reproducible in the sense that others can check and verify it as well as borrow, share and adapt it to their own work. Analysts can also repeat their own work as fresh data becomes available – there’s no need to recreate the wheel. The openness, efficiency and power of working in R offers the opportunity, if taken, to improve how road safety analysis gets done. Let’s be honest: like learning any new skill, effort is needed upfront to reap the benefits of this new way of working. But we firmly believe the effort it is worth it, and we think this manual is great way to get you started.\nSteve Gooding, Director, RAC Foundation",
    "crumbs": [
      "Preamble"
    ]
  },
  {
    "objectID": "index.html#preface",
    "href": "index.html#preface",
    "title": "Reproducible Road Safety Research with R",
    "section": "Preface",
    "text": "Preface\nMany areas of research have real world implications, but few have the ability to save lives in the way that road safety research does. Road safety research is a data driven field, underpinned by attribute-rich spatio-temporal event-based datasets representing the grim reality of people who are tragically hurt or killed on the roads. Because of the incessant nature of road casualties, there is a danger that it becomes normalised, an implicitly accepted cost associated with the benefits of personal mobility.\nData analysis in general and ‘data science’ in particular has great potential to support more evidence-based road safety policies. Data science can be defined as a particular type of data analysis process, in that it is script-based, reproducible and scalable. As such, it has the ability to represent what we know about road casualties in new ways, demonstrate the life-saving impacts of effective policies, and prioritise interventions that are most likely to work.\nThis manual was not designed to be a static textbook that is read once and accumulates dust. It is meant to be a hand-book, taken out into the field of applied research and referred to frequently in the course of an analysis project. As such, it is applied and exercise based.\nThere are strong links between data science, open data, open source software and more collaborative ways of working. As such, this book is itself a collaborative and open source project that is designed to be a living document. We encourage any comments, questions or contributions related to its contents, the source code of which can be found at the Reproducible Road Safety Research with R (rrsrr) repo on the ITSLeeds GitHub organisation, via the issue tracker. More broadly, we hope you enjoy the contents of the book and find the process of converting data science into data driven policy changes and investment rewarding. Get ready for the brave new reproducible world and enjoy the ride!\nRobin Lovelace, Leeds, Autumn 2020",
    "crumbs": [
      "Preamble"
    ]
  },
  {
    "objectID": "index.html#thanks",
    "href": "index.html#thanks",
    "title": "Reproducible Road Safety Research with R",
    "section": "Thanks",
    "text": "Thanks\nMany thanks to everyone who made this happen, especially RAC Foundation for funding the project, Malcolm Morgan and Andrea Gilardi for contributing to earlier versions, and the Department for Transport for funding reproducible road safety research through the SaferActive project.",
    "crumbs": [
      "Preamble"
    ]
  },
  {
    "objectID": "01-intro.html",
    "href": "01-intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 Reproducibility\nThis book teaches reproducible road safety analysis with R, a popular, free and open source statistical programming language. It was initially developed for a 2 day course, Introduction to R for Road Safety course. Since then, interest in the topic has grown. The RAC Foundation charity in the UK funded the development of this manual as a free and open resource to support their objective of making the roads safer for everyone. The content is based on open access road crash data from the UK, which is provided by the R package stats19. However, the content is designed to be general and should be of use to anyone working with road crash data worldwide, that has (at a minimum) the following variables (see Table 1.1 for an example crash dataset):\nClearly, work is needed to go from the raw data to evidence that can save lives. Although the datasets used in this guide report road casualty data from Britain, the approach knows no borders: R works equally well in China, India, the USA and Zambia. Road safety is a global issue, that can be considered an epidemic and “the leading cause of death for people aged between 5 and 29 years” worldwide, ahead of hunger, disease and war. The urgency and ubiquity of the ‘road violence’ epidemic is shown in Figure 1.1. Although Britain has relatively safe roads by international standards (with around 3 road traffic deaths per 100,000 people per year, compared with a global average of 17), it still sees over 1000 road deaths each year and unmeasurable costs to families who have lost loved ones and people left with permanent injuries due to poorly designed roads and transport policies.\nThe guide is practical, meaning that you should reproduce the examples that are provided throughout. As with many practical skills, you learn data science by doing data science.\nBefore getting stuck in with the practical content, which begins in Section 2, the remainder of this chapter:\nReproducible research can be defined as work that generates results that can be regenerated by others using publicly accessible code. By contrast, findings that cannot be repeated are not reproducible.\nReproducibility is not a binary concept, but a continuum. At one extreme, there is work that does not report the data source, methods or software. At the other end of that continuum, there are findings that can be reproduced in their entirety, including the production of figures and, as is the case with this manual, the manuscript/medium in which results are presented. Reproducibility can be built into every stage of quantitative research, as shown in Table 1.2.\nre = readr::read_csv(\"reproducibility.csv\")\n\nRows: 4 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): Research component, Requirement\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nknitr::kable(re)\nrm(re)\n\n\n\nTable 1.2: Four elements of reproducibility adapted from Peng, Dominici, and Zeger (2006).\n\n\n\n\n\n\n\n\n\n\nResearch component\nRequirement\n\n\n\n\nData\nDatasets used are available.\n\n\nMethods\nComputer code underlying figures, tables, etc are available. Software to execute that code is available.\n\n\nDocumentation\nDocumentation of the computer code, software environment, and methods for others to repeat and build on the analysis.\n\n\nDistribution\nStandard methods of distribution are used for others to access the software, data, and documentation.\nThe importance of reproducibility in scientific research should be obvious: if findings cannot be repeated, this casts doubt on the validity and truth of the conclusions drawn from them. Reproducibility is vital for falsifiability, a cornerstone of science.\nIn applied policy-relevant research areas, such as road safety research, reproducibility is equally important: policy makers and the public want to have confidence that the evidence underlying key decisions is reliable. Policies based on results that nobody can reproduce are harder to defend than policies that have a clear evidence base open for others to repeat, including members of the public and educators. In transport planning, open and reproducible methods support more transparent and democratically accountable interventions. Reproducibility leads to solid science, which is conducive to effective policies. In the context of road safety research, this means that reproducibility can save lives.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#what-is-r",
    "href": "01-intro.html#what-is-r",
    "title": "1  Introduction",
    "section": "1.2 What is R?",
    "text": "1.2 What is R?\nR is an open source programming language first developed by award-winning academic statisticians Dr Ross Ihaka and Professor Robert Gentleman. Since its first release in 1995 and the release of version 1.0.0 in 2000, R has seen rapid uptake. As of September 2020, R was ranked as the 9th most used programming language on the TIOBE Index, ahead of other languages for data processing, such as SQL and MATLAB, and behind general purpose languages such as C, Java and Python.\nAn important feature of R is that it was designed for data processing and statistical analysis. This means that you can undertake many aspects of road safety research using the core language. R is widely acknowledged to outperform other open languages for data science, such as Julia, Python and Scala, in terms of data visualisation and deployment of web applications for presenting data via the R package shiny. Furthermore, recently developed packages tidyverse and sf, provide a unified and user friendly system for working with attribute-rich and geographic datasets. Because road crash data is commonly attribute-rich and geographic, we will be using these packages in subsequent sections.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#why-r-for-road-safety-research",
    "href": "01-intro.html#why-r-for-road-safety-research",
    "title": "1  Introduction",
    "section": "1.3 Why R for road safety research?",
    "text": "1.3 Why R for road safety research?\nR is an outstanding language for reproducible research. It is accessible with no licensing restrictions and easy installation procedures on a wide range of computers, including most versions of Windows, Mac and Linux operating systems. Furthermore, R is highly extensible. With 15,000+ packages available, many of which are developed by professional statisticians and domain experts, R provides access to a wide array of statistical, computational and visualisation techniques. Many packages, such as markdown and reprex, were designed to support more reproducible research.\nFrom a road safety perspective, R is well suited to handling data structures used in road safety research. R excels at the processing, analysis, modelling and visualisation of large spatio-temporal and attribute-rich datasets of the type key to road safety research. R is a mature and growing tool for data science, popular in industry, academia and government, so it creates multiple opportunities for collaboration within and between organisations and internationally.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#prerequisites",
    "href": "01-intro.html#prerequisites",
    "title": "1  Introduction",
    "section": "1.4 Prerequisites",
    "text": "1.4 Prerequisites\nYou do not need to be a professional programmer, data scientist or computer wizard to use R for road safety research. If you have primarily used graphical user interfaces (GUIs), such as Microsoft Excel, it may take some time to get used to the code-based R approach. However, the command-line interface (CLI) of R is no ‘harder’ than the incessant pointing and clicking demanded by tools such as Excel and web-based GUIs for road safety research. It takes time to adapt to new ways of working, and R has a steep learning curve at the outset. However, persevering can be very rewarding: proficiency with R’s CLI is a future-proof and transferable skill that can yield huge productivity gains. Perhaps the most important prerequisite, therefore, is time and a willingness to try new ways of working.\nThe good news is that it has never been easier to learn and install R, as highlighted in the stats19-training-setup that can be found on the stats19 package website at docs.ropensci.org/stats19.\nIt is important to have an up-to-date version of R installed before proceeding to the practical sections of this manual. Note that, like any actively developed software, R is evolving so it is worth updating or re-installing R/RStudio every year or so and updating your R packages every month or so to ensure you have the latest software.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#installing-r-and-rstudio",
    "href": "01-intro.html#installing-r-and-rstudio",
    "title": "1  Introduction",
    "section": "1.5 Installing R and RStudio",
    "text": "1.5 Installing R and RStudio\nTo complete the exercises in this guide, you will need to install:\n\nR from cran.r-project.org\nRStudio from rstudio.com\nR packages, by opening RStudio and typing install.packages(\"stats19\") in the console to install the stats19 package, for example (see Section 4 for details)\n\nWe recommend using at least the latest stable release of R (4.0.3 at the time of writing in 2020). If you’re running on macOS or Linux, you may need to install additional dependencies, as documented in blog posts and documentation pages such as Installation of R 4.0 on Ubuntu 20.04 LTS and tips for spatial packages and the Installing section of the github.com/r-spatial/sf package README page. We recommend running R on a decent computer, with at least 4 GB RAM and ideally 8 GB or more RAM. R is computationally efficient and therefore fast language for data science but, because of the size of some road safety datasets, we recommend using it on a high spec laptop or desktop.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#r-in-the-cloud",
    "href": "01-intro.html#r-in-the-cloud",
    "title": "1  Introduction",
    "section": "1.6 R in the cloud",
    "text": "1.6 R in the cloud\nIf you do not have access to a suitable computer on which you can install R, or just want to get up-and-running quickly, you can run R in the cloud.\nVarious organisations manage RStudio Server instances, but by far the most well-known cloud provider is at cloud.rstudio.com. To run R in the cloud, sign-up to cloud.rstudio.com (or cloud instance of your choice) and access RStudio from the browser.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#recommended-packages",
    "href": "01-intro.html#recommended-packages",
    "title": "1  Introduction",
    "section": "1.7 Recommended packages",
    "text": "1.7 Recommended packages\nOf the thousands of available packages that are available for road safety research, we will use a handful that are mature, well-tested and well-suited to statistical analysis and visualisation of road casualty data. For the first practical steps, in Section 2, all you need is a working version of R and RStudio. In Section 4 we will see how to install and use add-on packages such as stats19. If you want to be ahead of the game, you can check that you have the necessary packages installed by running the following commands, which install and load the packages that we will use for the course:\n\ninstall.packages(\"remotes\") # installs the remotes package\npkgs = c(\n  \"stats19\",     # downloads and formats open stats19 crash data\n  \"sf\",          # spatial data package\n  \"tidyverse\",   # a 'metapackage' with many functions for data processing\n  \"tmap\",        # for making maps\n  \"pct\",         # access travel data from DfT-funded PCT project \n  \"stplanr\"      # transport planning tools\n)\n\nremotes::install_cran(pkgs)\nlapply(pkgs, library, character.only = TRUE)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "01-intro.html#overview",
    "href": "01-intro.html#overview",
    "title": "1  Introduction",
    "section": "1.8 Overview",
    "text": "1.8 Overview\nThe rest of the manual is structured as follows.\n\nSection 2 introduces the basics of the R language. While not essential reading for people who already have experience with R or who just want to get stuck-in to importing datasets, as per Section 5, it is recommended reading even if you already use R. This section introduces key aspects of the R language that may not be needed for basic data analysis tasks, but which will be vital when ‘debugging’ your code (the process you go through to remove bugs/mistakes). It provides a strong foundation for subsequent sections.\nSection 3 provides a brief introduction to productive research workflows using RStudio, an advanced integrated development environment for not only writing R code, but also for project management and boosting your productivity with a suite of features that puts Excel to shame.\nSection 4 introduces the stats19 package and other R packages we will be using in subsequent chapters.\nSection 5 demonstrates key data processing techniques using tidyverse.\nSection 6 teaches key functions for working with timestamps.\nSection 7 shows how you can create maps and perform geographic data analysis with road crash data in R.\nSection 8 provides an introduction to joining road crash data, with a focus on casualty and accident tables in STATS19 data (introduced in Section 4).\nSection 9 suggests next steps for road safety researchers looking to take their skills to the next levels and provide the strong evidence needed to save lives.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "02-basics.html",
    "href": "02-basics.html",
    "title": "2  R basics",
    "section": "",
    "text": "2.1 Creating and removing R objects\nLearning a programming language is like learning any language. If you’re learning French, for example, you could just dive in and start gesticulating to people in central Paris. However, it’s worth taking the time to understand the structure and key words of the language first. The same applies to data science: it will help if you first understand a little about the syntax and grammar of the language that we will use to in relation to the ‘data’ (the statistical programming language R) before diving into using it for road safety research. This section, parts of which were originally developed for a 2 day course on data science, may seem tedious for people who just want to crack on and load-in data. However, working through the examples below is recommended for most people unless you’re already an experienced R user, although even experienced R users may learn something about the language’s syntax and fundamental features.\nThe first step is to start RStudio, e.g. if you are on Windows, this can be achieved by tapping Start and searching for RStudio. You should see an R console pane like that which is displayed in Figure 2.1.\nIf you saw something like that which is shown in Figure 2.1 congratulations! You are ready to start running R code by entering commands into the console.\nR can be understood as a giant calculator. If you feed the console arithmetic tasks, it will solve them precisely and instantly. Try typing the following examples (note that pi is an inbuilt object) into the R console in RStudio and pressing Enter to make R run the code. (Note: The output of the code, when shown in this manual, is preceeded by ‘##’.)\n2 + 19\n\n[1] 21\n\npi^(19 + 2) / exp(2 + 19) \n\n[1] 20.89119\nUse the same approach to find the square route of 361 (answer not shown):\nsqrt(361)\nThis is all well and good, providing a chance to see how R works with numbers and to get some practice with typing commands into the console. However, the code chunks above do not make use of a key benefit of R: it is object oriented, meaning it stores values and complex objects, such as data frames representing road casualties, and processes them in memory (meaning that R is both fast and memory hungry when working with large datasets). If you are more familiar with Excel, a data frame may be thought of as fulfilling the purpose of a single worksheet containing a set of data.\nThe two most common ways of creating objects are using &lt;- ‘arrow’ or = ‘equals’ assignment. These symbols are assignment operators because they assign contents, such as numbers, to named objects. We advocate using snake_case, a style that avoids upper case characters to ease typing and uses the underscore symbol (_) to clearly demarcate spaces between words.\nThe objects created in the previous code chunk have now served their purpose, which is to demonstrate basic object creation in R. So, based on the wise saying that tidying up is the most important part of a job, we will now remove these objects:\nx = 2\ny = 19\nz = x + y\npi^z / exp(z)\n\n[1] 20.89119\n\nrm(x, y, z)\nWhat just happened? We removed the objects using the R function rm(), which stands for ‘remove’. A function is an instruction or set of instructions for R to do something with what we give to that function. What we give to the function are known as arguments. Each function has set of arguments we can potentially give to it.\nTechnically speaking, we passed the objects to arguments in the rm() function call. In plain English, things that go inside the curved brackets that follow a function name are the arguments. The rm() function removes the objects that it is passed (most functions modify objects). A ‘nuclear option’ for cleaning your workspace is to run the following command, the meaning of which you will learn in the next section. (Can you guess?)\nrm(list = ls())\nNext exercise: create objects that more closely approximate road casualty data by typing and running the following lines of code in the console:\ncasualty_type = c(\"pedestrian\", \"cyclist\", \"cat\")\ncasualty_age = seq(from = 20, to = 60, by = 20)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R basics</span>"
    ]
  },
  {
    "objectID": "02-basics.html#object-types-vectors-and-data-frames",
    "href": "02-basics.html#object-types-vectors-and-data-frames",
    "title": "2  R basics",
    "section": "2.2 Object types: vectors and data frames",
    "text": "2.2 Object types: vectors and data frames\nThe final stage in the previous section involved creating two objects with sensible names in our R session. After running the previous code chunk the casualty_* objects are in the workspace (technically, the ‘global environment’). You should be able to see the object names in the Environment tab in the top right of RStudio. Objects can also be listed with the ls() command as follows:\n\nls()\n\n[1] \"casualty_age\"  \"casualty_type\"\n\n\nThe previous command executed the function ls() with no arguments. This helps explain the command rm(list = ls()), which removed all objects in the global environment in the previous section. This also makes the wider point that functions can accept arguments (in this case the list argument of the rm() function) that are themselves function calls.\nTwo key functions for getting the measure of R objects are class() and length().\n\nclass(casualty_type)\n\n[1] \"character\"\n\nclass(casualty_age)\n\n[1] \"numeric\"\n\n\nThe class of the casualty_type and casualty_type objects are character (meaning text) and numeric (meaning numbers), respectively. The objects are vectors, a sequence of values of the same type. Next challenge: guess their length and check your guess was correct by running the following commands (results not shown):\n\nlength(casualty_type)\nlength(casualty_age)\n\nTo convert a series of vectors into a data frame with rows and columns (similar to an Excel worksheet), we will use the data.frame() function. Create a data frame containing the two casualty vectors as follows:\n\ncrashes = data.frame(casualty_type, casualty_age)\n\nWe can see the contents of the new crashes object by entering the following line of code. This prints its contents (results not shown, you need to run the command on your own computer to see the result):\n\ncrashes\n\nWe can get a handle of data frame objects such as crashes as follows:\n\nclass(crashes)\n\n[1] \"data.frame\"\n\nnrow(crashes)\n\n[1] 3\n\nncol(crashes)\n\n[1] 2\n\n\nThe results of the previous commands tell us that the dataset has 3 rows and 2 columns. We will use larger datasets (with thousands of rows and tens of columns) in later sections, but for now it’s good to ‘start small’ to understand the basics of R.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R basics</span>"
    ]
  },
  {
    "objectID": "02-basics.html#subsetting-by-index-or-column-name",
    "href": "02-basics.html#subsetting-by-index-or-column-name",
    "title": "2  R basics",
    "section": "2.3 Subsetting by index or column name",
    "text": "2.3 Subsetting by index or column name\nAs we saw above, the most basic type of R object is a vector, which is a sequence of values of the same type such as the numbers in the object casualty_age. In the earlier examples, x, y and z were all numeric vectors with a length of 1; casualty_type is a character vector (because it contains letters that cannot be added) of length 3; and casualty_age is a numeric vector of length 3.\nSubsetting means ‘extracting’ only part of a vector or other object, so that only the parts of most interest are returned to us. Subsets of vectors can be returned by providing numbers representing the positions (index) of the elements within the vector (e.g. ‘2’ representing selection of the 2nd element) or with logical (TRUE or FALSE) values associated with the element. These methods are demonstrated below, to return the 2nd element of the casualty_age object is returned:\n\ncasualty_age\n\n[1] 20 40 60\n\ncasualty_age[2]\n\n[1] 40\n\ncasualty_age[c(FALSE, TRUE, FALSE)]\n\n[1] 40\n\n\nTwo dimensional objects such as matrices and data frames can be subset by rows and columns. Subsetting in base R is achieved by using square brackets [] after the name of an object. To practice subsetting, run the following commands to index and column name and verify that you get the same results to those that are shown below.\n\ncasualty_age[2:3] # second and third casualty_age\ncrashes[c(1, 2), ] # first and second row of crashes\ncrashes[c(1, 2), 1] # first and second row of crashes, first column\ncrashes$casualty_type # returns just one column\n\nThe final command used the dollar symbol ($) to subset a column. We can use the same symbol to create a new column as follows:\n\nvehicle_type = c(\"car\", \"bus\", \"tank\")\ncrashes$vehicle_type = vehicle_type\nncol(crashes)\n\n[1] 3\n\n\nNotice that the dataset now has three columns after we added one to the right of the previous one. Note also that this would involve copying and pasting cells in Excel, but in R it is instant and happens as fast as you can type the command. To confirm that what we think has happened has indeed happened, print out the object again to see its contents:\n\ncrashes\n\n  casualty_type casualty_age vehicle_type\n1    pedestrian           20          car\n2       cyclist           40          bus\n3           cat           60         tank\n\n\nIn Section 5 we will use filter() and select() functions to subset rows and columns. Before we get there, it is worth practicing subsetting using the square brackets to consolidate your understanding of how base R works with vector objects such as vehicle_type and data frames such as crashes. If you can answer the following questions, congratulations, you are ready to move on. If not, it’s worth doing some extra reading and practice on the topic of subsetting in base R.\nExercises\n\nUse the $ operator to print the vehicle_type column of crashes.\nSubset the crashes with the [,] syntax so that only the first and third columns of crashes are returned.\nReturn the 2nd row and the 3rd column of the crashes dataset.\nReturn the 2nd row and the columns 2:3 of the crashes dataset.\nBonus: what is the class() of the objects created by each of the previous exercises?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R basics</span>"
    ]
  },
  {
    "objectID": "02-basics.html#subsetting-by-values",
    "href": "02-basics.html#subsetting-by-values",
    "title": "2  R basics",
    "section": "2.4 Subsetting by values",
    "text": "2.4 Subsetting by values\nIt is also possible to subset objects by the values of their elements. This works because the [ operator accepts logical vectors returned by queries such as ‘Is it less than 3?’ (x &lt; 3 in R) and ‘Was it light?’ (crashes$dark == FALSE), as demonstrated below:\n\nx[c(TRUE, FALSE, TRUE, FALSE, TRUE)] # 1st, 3rd, and 5th element in x\nx[x == 5] # only when x == 5 (notice the use of double equals)\nx[x &lt; 3] # less than 3\nx[x &lt; 3] = 0 # assign specific elements\ncasualty_age[casualty_age %% 6 == 0] # just the ages that are a multiple of 6\ncrashes[crashes$dark == FALSE, ] # just crashes that occured when it wasnt dark\n\nExercises\n\nSubset the casualty_age object using the inequality (&lt;) so that only elements less than 50 are returned.\nSubset the crashes data frame so that only tanks are returned using the == operator.\nBonus: assign the age of all tanks to 61.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R basics</span>"
    ]
  },
  {
    "objectID": "02-basics.html#dealing-with-nas-and-recoding",
    "href": "02-basics.html#dealing-with-nas-and-recoding",
    "title": "2  R basics",
    "section": "2.5 Dealing with NAs and recoding",
    "text": "2.5 Dealing with NAs and recoding\nR objects can have a value of NA. NA is how R represents missing data.\n\nz = c(4, 5, NA, 7)\n\nNA values are common in real-world data but can cause trouble. For example:\n\nsum(z) # result is NA\n\nSome functions can be told to ignore NA values.\n\nsum(z, na.rm = TRUE) # result is equal to 4 + 5 + 7\n\nYou can find NAs using the is.na() function, and then remove them:\n\nis.na(z)\nz_no_na = z[!is.na(z)] # note the use of the not operator !\nsum(z_no_na)\n\nIf you remove records with NAs, be warned: the average of a value excluding NAs may not be representative.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R basics</span>"
    ]
  },
  {
    "objectID": "02-basics.html#changing-class",
    "href": "02-basics.html#changing-class",
    "title": "2  R basics",
    "section": "2.6 Changing class",
    "text": "2.6 Changing class\nSometimes you may want to change the class of an object. This is called class coercion, and can be done with functions such as as.logical(), as.numeric() and as.matrix().\nExercises\n\nCoerce the vehicle_type column of crashes to the class character.\nCoerce the crashes object into a matrix. What happened to the values?\nBonus: What is the difference between the output of summary() on character and factor variables?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R basics</span>"
    ]
  },
  {
    "objectID": "02-basics.html#recoding-values",
    "href": "02-basics.html#recoding-values",
    "title": "2  R basics",
    "section": "2.7 Recoding values",
    "text": "2.7 Recoding values\nOften it is useful to ‘recode’ values. In the raw STATS19 files, for example, -1 means NA. There are many ways to recode values in R, the simplest and most mature of which is the use of ‘factors’, which are whole numbers representing characters. Factors are commonly used to manage categorical variables such as sex, ethnicity or, in road traffic research, vehicle type or casualty injury severity.\n\nz = c(1, 2, -1, 1, 3)\nl = c(NA, \"a\", \"b\", \"c\") # labels in ascending order\nz_factor = factor(z, labels = l) # factor z using labels l\nz_character = as.character(z_factor) # convert factors to characters\nz_character\n\n[1] \"a\" \"b\" NA  \"a\" \"c\"\n\n\nExercises\n\nRecode z to Slight, Serious and Fatal for 1:3 respectively.\nBonus: read the help file at ?dplyr::case_when and try to recode the values using this function.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R basics</span>"
    ]
  },
  {
    "objectID": "02-basics.html#saving-r-objects",
    "href": "02-basics.html#saving-r-objects",
    "title": "2  R basics",
    "section": "2.8 Saving R objects",
    "text": "2.8 Saving R objects\nYou can also save individual R objects as .Rds files. The .Rds format is the data format for R, meaning that any R object can be saved as an Rds file, equivalent to saving an Excel spreadsheet as a .xlsx file. The following command saves the crashes dataset into a compressed file called crashes.Rds:\n\nsaveRDS(crashes, \"crashes.Rds\")\n\nTry reading in the data just saved, and checking that the new object is the same as crashes, as follows:\n\ncrashes2 = readRDS(\"crashes.Rds\")\nidentical(crashes, crashes2)\n\n[1] TRUE\n\n\nR also supports many other formats, including CSV files, which can be created and imported with the functions readr::read_csv() and readr::write_csv() (see also the readr package).\n\nreadr::write_csv(crashes, \"crashes.csv\") # uses the write_csv function from the readr package\ncrashes3 = readr::read_csv(\"crashes.csv\")\nidentical(crashes3, crashes) \n\nNotice that crashes3 and crashes are not identical. What has changed? Hint: read the help page associated with ?readr::write_csv.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R basics</span>"
    ]
  },
  {
    "objectID": "02-basics.html#now-you-are-ready-to-use-rstudio",
    "href": "02-basics.html#now-you-are-ready-to-use-rstudio",
    "title": "2  R basics",
    "section": "2.9 Now you are ready to use RStudio",
    "text": "2.9 Now you are ready to use RStudio\nBonus: reproduce the following plot by typing the following code into the console.\n\neyes = c(2.3, 4, 3.7, 4)\neyes = matrix(eyes, ncol = 2, byrow = T)\nmouth = c(2, 2, 2.5, 1.3, 3, 1, 3.5, 1.3, 4, 2)\nmouth = matrix(mouth, ncol = 2, byrow = T)\nplot(eyes, type = \"p\", main = \"RRR!\", cex = 2, xlim = c(1, 5), ylim = c(0, 5))\nlines(mouth, type = \"l\", col = \"red\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>R basics</span>"
    ]
  },
  {
    "objectID": "03-rstudio.html",
    "href": "03-rstudio.html",
    "title": "3  Using RStudio",
    "section": "",
    "text": "3.1 Projects and scripts\nThe previous section taught the basics of the R language. We entered and ran commands directly in the console. In this section we will learn how to write R scripts in RStudio’s source editor. We will also take a step back and considers how R code fits into the wider context of scripts, projects, and getting help in RStudio. RStudio is an integrated development environment (IDE) for R that makes it easy to create and run scripts, explore R objects and functions, plot results and get help.\nThe first exercise is to open RStudio, take a look around, identify and explore the main components, shown in Figure 3.1. Click on different buttons in RStudio’s GUI and try changing the Global Settings (in the Tools menu) and see RStudio’s shortcuts by pressing Alt-Shift-K (or Option+Shift+K on Mac).\nProjects organise files and settings in RStudio into folders. Each project has its own folder and Rproj file. When using RStudio, always ensure you are working in a named project to organise your work. Start a new project with by clicking on File &gt; New Project in RStudio’s top menu. You create projects either in a new or existing directory (folder). Make a new project called ‘lrrsrr’ (short for ‘learning reproducible road safety research with R’) or a name of your choice and save it in a sensible place on your computer. The name of the project will appear in the top right of RStudio.\n‘Scripts’ are files where R code are stored, and these can be edited in the Source Editor panel (the top left panel in Figure 3.1). Keeping your code in sensibly named, well organised and reproducible scripts will make your life easier. We could continue typing all our code into the console, as we did in Section 2. However, that approach is limited when working on anything more complicated than a few simple commands. Code that you want to keep and share should be saved script files, i.e. plain text files that have the .R extension.\nMake a new script by typing and running this command in the R console:\nfile.edit(\"section3.R\")\nThis will open the Source Editor and place your cursor there. Try jumping between the Source Editor and the Console by pressing Ctl+1 and Ctl+2.\nKeeping scripts and other files associated with a project in a single folder per project (in an RStudio project) will help you to locate things you need and develop an efficient workflow. Next, to check that your project is saved, close RStudio.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Using RStudio</span>"
    ]
  },
  {
    "objectID": "03-rstudio.html#writing-and-running-code",
    "href": "03-rstudio.html#writing-and-running-code",
    "title": "3  Using RStudio",
    "section": "3.2 Writing and running code",
    "text": "3.2 Writing and running code\nRe-open RStudio and ensure that you have an empty file open in the Source Editor. We will type some basic commands into this file. Type the following lines of code into your new section3.R R script and execute the result line-by-line by pressing Ctrl+Enter (Command+Enter on Mac):\n\nx = 1:5\ny = c(0, 1, 3, 9, 18)\nplot(x, y)\n\nWhen the code has been sent to the console, two objects are created, both of which are vectors of 5 elements (Bonus: check their length using the length() function). The third line of the code chunk plots them. Save the script by pressing Ctrl+S.\nThere are several ways to run code within a script and it is worth becoming familiar with each. Try running the code you saved in the previous section using each of these methods:\n\nPlace the cursor in different places on each line of code and press Ctrl+Enter to run that line of code.\nHighlight a block of code or part of a line of code and press Ctrl+Enter to run the highlighted code.\nPress Ctrl+Shift+Enter to run all the code in a script.\nSelect Run on the toolbar to run all the code in a script.\nBonus: Use the function source() to run all the code in a script e.g. source(\"section3.R\")\n\nPractice alternating between the console and the source editor by pressing Ctl+1 and Ctl+2.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Using RStudio</span>"
    ]
  },
  {
    "objectID": "03-rstudio.html#viewing-objects",
    "href": "03-rstudio.html#viewing-objects",
    "title": "3  Using RStudio",
    "section": "3.3 Viewing Objects",
    "text": "3.3 Viewing Objects\nTo practice typing code into scripts, rather than into the console, we will re-create the objects we created in Section 2. Create a new script called objects.R and type the following commands, character-for-character, including spaces in the right places. Typing rather than copy-pasting will help develop good coding style and speed:\n\nvehicle_type = c(\"car\", \"bus\", \"tank\")\ncasualty_type = c(\"pedestrian\", \"cyclist\", \"cat\")\ncasualty_age = seq(from = 20, to = 60, by = 20)\nset.seed(1)\ndark = sample(x = c(TRUE, FALSE), size = 3, replace = TRUE)\nsmall_matrix = matrix(1:24, nrow = 12)\ncrashes = data.frame(vehicle_type, casualty_type, casualty_age, dark)\n\nRun the code line-by-line by pressing Ctl+Enter multiple times, as described in the previous section. Try viewing the objects in the following ways:\n\nType the name of the object into the console, e.g. crashes and small_matrix, and run that code. Scroll up to see the numbers that didn’t fit on the screen.\nUse the head() function to view just the first 6 rows e.g. head(small_matrix)\nBonus: use the n argument in the previous function call to show only the first 2 rows of small_matrix\nClick on the crashes object in the environment tab to View it in a spreadsheet.\nRun the command View(vehicle_type). What just happened?\n\nWe can also get an overview of an object using a range of functions, including:\n\nsummary()\nclass()\ntypeof()\ndim()\nlength()\n\nView a summary of the casualty_age variable by running the following line of code (you should see the same output as shown below):\n\nsummary(casualty_age)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n     20      30      40      40      50      60 \n\n\nExercise: use the functions listed above (class() to length()) to test the basic R functions and extract key information about the object vehicle_type. What does the output tell us about the object?",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Using RStudio</span>"
    ]
  },
  {
    "objectID": "03-rstudio.html#autocompletion",
    "href": "03-rstudio.html#autocompletion",
    "title": "3  Using RStudio",
    "section": "3.4 Autocompletion",
    "text": "3.4 Autocompletion\nRStudio can help you write code by autocompleting it. RStudio will look for similar objects and functions after typing the first three letters of a name.\n\nknitr::include_graphics(\"figures/autocomplete.jpg\")\n\n\n\n\n\n\n\nFigure 3.2\n\n\n\n\n\nWhen there is more than one option, you can select from the list using the mouse or arrow keys. Within a function, you can get a list of arguments by pressing Tab.\n\nknitr::include_graphics(\"figures/functionhelp.jpg\")\n\n\n\n\n\n\n\nFigure 3.3\n\n\n\n\n\nTest RStudio’s amazing autocompletion capabilities by typing the beginning of object names and functions and pressing Tab to see what suggestions pop-up. Try pressing Up and Down after pressing Tab to select different options.\nBonus: try autocompleting file names by typing \"\" (the closing quote mark should be added automatically) and pressing Tab when your cursor is between the quote marks. What happens when you type \"~/\" and press Tab with your cursor just after the tilde (~) symbol. What does this mean? (Hint: it involves the word ‘home’ and you can search the web to find a full answer)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Using RStudio</span>"
    ]
  },
  {
    "objectID": "03-rstudio.html#getting-help",
    "href": "03-rstudio.html#getting-help",
    "title": "3  Using RStudio",
    "section": "3.5 Getting help",
    "text": "3.5 Getting help\nEvery function in R has a help page. You can view the help using ?. For example, ?sum and ?plot. Many packages also contain ‘vignettes’, which are long form help documents containing examples and guides. vignette() will show a list of all the vignettes available, or you can also view a specific vignette. For example, vignette(topic = \"sf1\", package = \"sf\").\nTry getting help on the stats19 package by typing the following and pressing Tab when your cursor is just to the left of the closing bracket ). Autocompletion works for more than just R objects and files - try making RStudio autocomplete and run the command vignette(\"stats19-vehicles\"). For example:\n\nvignette(stats19)\n\nYou can further search and explore R’s help files using the Help panel in the bottom right window in RStudio.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Using RStudio</span>"
    ]
  },
  {
    "objectID": "03-rstudio.html#commenting-code",
    "href": "03-rstudio.html#commenting-code",
    "title": "3  Using RStudio",
    "section": "3.6 Commenting Code",
    "text": "3.6 Commenting Code\nIt is good practice to use comments in your code to explain what it does. You can comment code using #\nFor example:\n\n# Create vector objects (a whole line comment)\nx = 1:5 # a seqence of consecutive integers (inline comment)\ny = c(0, 1, 3, 9, 18.1) \n\nYou can comment/uncomment a whole block of text by selecting it and using Ctrl+Shift+C.\nPro tip: You can add a comment section using Ctrl+Shift+R.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Using RStudio</span>"
    ]
  },
  {
    "objectID": "03-rstudio.html#the-global-environment",
    "href": "03-rstudio.html#the-global-environment",
    "title": "3  Using RStudio",
    "section": "3.7 The global environment",
    "text": "3.7 The global environment\nThe ‘Environment’ tab shows all the objects in your environment. This includes datasets, parameters, and any functions you have created. By default, new objects appear in the Global Environment, but you can see other environments with the dropdown menu. For example, each package has its own environment.\nSometimes you wish to remove things from your environment, perhaps because you no longer need them or because things are getting cluttered.\nYou can remove an object with the rm() function e.g. rm(x) or rm(x, y). Alternatively, you can clear your whole environment with the ‘broom’ button on the ‘Environment’ Tab.\n\nRemove the object x that was created in a previous section.\nWhat happens when you try to print the x by entering it into the console?\nTry running the following commands in order: save.image(); rm(list = ls()); load(\".RData\"). What happened?\nHow big (how many bytes) is the .RData file in your project’s folder?\nTidy up by removing the .Rdata file with file.remove(\".Rdata\").",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Using RStudio</span>"
    ]
  },
  {
    "objectID": "03-rstudio.html#debugging-code",
    "href": "03-rstudio.html#debugging-code",
    "title": "3  Using RStudio",
    "section": "3.8 Debugging Code",
    "text": "3.8 Debugging Code\nAll the code shown so far is reproducible and, unless you introduced typos, is ‘bug free’, meaning that it runs without errors. Typos are common though and even experienced R users frequently see error messages as they undertake interactive data analysis. For that reason, learning to fix typos in R code is an important skill. RStudio comes to the rescue here with helpful debugging features. To test them, write some code that fails, as shown in the code chunk and exercises below, then answer the questions below by interacting with RStudio:\n\nx = 1:5\ny = c(0, 1, 3, 9 18.1) # R code with a typo\n\nError in parse(text = input): &lt;text&gt;:2:18: unexpected numeric constant\n1: x = 1:5\n2: y = c(0, 1, 3, 9 18.1\n                    ^\n\n\n\nknitr::include_graphics(\"figures/rstudio-autocomplete.png\")\n\n\n\n\n\n\n\nFigure 3.4: Debugging code with RStudio: notice the wavy red line highlighting a typo.\n\n\n\n\n\n\nTry running the faulty code. How can the error message help debug the code?\nWhat is the problem with the code shown in the figure?\nCreate other types of error in the code you have run (e.g. no symetrical brackets and other typos).\nDoes RStudio pick up on the errors? And what happens when you try to run buggy code?\n\nAlways address debugging prompts to ensure your code is reproducible",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Using RStudio</span>"
    ]
  },
  {
    "objectID": "03-rstudio.html#productivity-boosting-features",
    "href": "03-rstudio.html#productivity-boosting-features",
    "title": "3  Using RStudio",
    "section": "3.9 Productivity boosting features",
    "text": "3.9 Productivity boosting features\nFinally, we look at functionality in RStudio that goes beyond the features described above. RStudio is an advanced and powerful IDE and is highly customisable in myriad ways, especially since the launch of the RStudio Addins add-on system in 2016. Rather than try to be comprehensive (an impossible task), this section provides a list of additional RStudio features, starting simple, that have been tried and tested, with links to the relevant documentation rather than extended descriptions.\n\nZoom levels and appearance settings: it is important for code and other text to be the right size. Too small and it’s hard to see, too big and you end up frequently scrolling up and down. The appropriate text size varies: if you’re doing a screen share, big text is appropriate; if you’re writing copious amounts of text (as I was when writing this prose in RStudio), smaller text will be handy. On Windows and Linux you can zoom with the shortcuts Ctl+Shift++ and Ctl+- for zooming in and out respectively. See ‘Tools &gt; Global Options’ menu (which can be launched with the shortcut Alt+T and then G) for more advanced ‘Appearance’ settings.\nGlobal search (and replace): in addition to search and replace functionality for single files (accessed in the standard way, by pressing Ctl+F), RStudio has a powerful global search feature inbuilt. Launch this feature by pressing Ctl+Shift+F and you can search any file types (e.g. only files ending in .R) for any string within an entire project. This feature is very handy when working with large, multi-file projects.\nShortcuts: there are many, many shortcuts built into RStudio. In fact, there is even a shortcut to show the list of shortcuts. Try pressing Alt+Shift+K to get the complete list. Nobody I know can remember, let alone use, all of these. However, over time I expect that you will learn to love some of them. My top 5 RStudio-specific shortcuts are:\n\nCtl+Enter to send a line of code from the code editor (called the Source Editor in RStudio) to be executed or ‘run’ in the console. Amazingly, some other prominent IDEs such as Microsoft’s VSCode editor, lack this important feature by default.\nCtl+1 and Ctl+2 to switch between the console (for writing test code and ‘run once’ commands) and the code editor (for writing code to keep).\nAlt+Up/Down and Alt+Shift+Up/Down to move and copy lines of code up and down, handy when you want to re-order your code or make small changes to a copy of a line of code.\nCtl+Shift+M will create the pipe operator (%&gt;%, this pipe was created using the shortcut!), saving time when creating dplyr pipelines, as discussed in Section 5.\nCtl+Shift+F10 when you want to restart R, leaving you with a ‘blank slate’ in which packages are not loaded and objects are removed from the global environment.\n\nGit integration for collaboration: RStudio provides two mechanisms for sharing your code with others via sites such as GitHub and GitLab, with the ‘Git’ panel in the top right pane and via the Terminal panel described in the next section.\nSupport for Python, C++ and other languages: a joke on Twitter said “What’s the best Python editor? RStudio.” Although most Python programmers would probably disagree, the joke is true in the sense that R has good support for some other languages: Python and C++ in particular. If you open a Python script in RStudio on a computer that has Python and the reticulate R package installed, the R console will magically convert into a Python console when you press Ctl+Enter to execute a line of Python code, as described in the article “Reticulated Python” on the RStudio website.\n\nLike R package, an active community of developers is developing a range of extensions and RStudio itself is gradually evolving to meet the evolving needs of 21st Century data scientists. If there are any features that you would like to see, you can always ask others for pointers, e.g. on the RStudio Community forum.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Using RStudio</span>"
    ]
  },
  {
    "objectID": "04-pkgs.html",
    "href": "04-pkgs.html",
    "title": "4  R packages",
    "section": "",
    "text": "4.1 What are packages?\nR has over 15,000 packages published on the official ‘CRAN’ site and many more published on code sharing sites such as GitHub. Packages are effectively plugins for R that extend it in many ways. Packages are useful because they enhance the range of things you can do with R, providing additional functions, data and documentation that build on the core (known as ‘base’) R packages. They range from general-purpose packages, such as tidyverse and sf, to domain-specific packages, such as stats19.\nThis chapter demonstrates the package lifecycle with reference stats19 and provides a taster of R’s visualisation capabilities for general purpose packages ggplot2 and dplyr. The stats19 package is particularly relevant for reproducible road safety research: its purpose is to download and clean road traffic collision data from the UK’s Department for Transport. Domain-specific packages, such as stats19, are often written by subject-matter experts, providing tried and tested solutions within a particular specialism. Packages are reviewed by code experts prior to being made available via CRAN.\nRegardless of whichever packages you install and use, you will take the following steps:\nOf these, the third stage takes by far the most amount of time. Stages 1, 2 and 4 are equally important, however; you cannot use a package unless it has been properly installed, loaded and, to get the best performance out of the latest version, updated when new versions are released. We will learn each of these stages of the package lifecycle with the stats19 package.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>R packages</span>"
    ]
  },
  {
    "objectID": "04-pkgs.html#what-are-packages",
    "href": "04-pkgs.html#what-are-packages",
    "title": "4  R packages",
    "section": "",
    "text": "installing the package;\nloading the package;\nusing the package; and\nupdating the package.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>R packages</span>"
    ]
  },
  {
    "objectID": "04-pkgs.html#the-stats19-r-package",
    "href": "04-pkgs.html#the-stats19-r-package",
    "title": "4  R packages",
    "section": "4.2 The stats19 R package",
    "text": "4.2 The stats19 R package\nLike many packages, stats19 was developed to meet a real world need. STATS19 data is provided as a free and open resource by the Department for Transport, encouraging evidence-based and accountable road safety research and policy interventions. However, researchers at the University of Leeds found that repeatedly downloading and formatting open STATS19 data was time-consuming, taking valuable resources away from more valuable (and fun) aspects of the research process. Significantly, manually recoding the data was error prone. By packaging code, we found that we could solve the problem in a free, open and reproducible way for everyone.\nBy abstracting the process to its fundamental steps (download, read, format), the stats19 package makes it easy to get the data into appropriate formats (of classes tbl, data.frame and sf), ready for further processing and analysis. The package built upon previous work, with several important improvements, including the conversion of crash data into geographic data in a sf data frame for geographic research. It enables creation of geographic representations of crash data, geo-referenced to the correct coordinate reference system, in a single function called format_sf(). Part-funded by the RAC Foundation, the package should be of use to academic researchers and professional road safety data analysts working at local authority and national levels in the UK.\nThe following sections demonstrate how to install, load and use packages with reference to stats19. This information can be applied in relation to any package.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>R packages</span>"
    ]
  },
  {
    "objectID": "04-pkgs.html#installing-packages",
    "href": "04-pkgs.html#installing-packages",
    "title": "4  R packages",
    "section": "4.3 Installing packages",
    "text": "4.3 Installing packages\nThe stats19 package is available on CRAN. This means that it has a web page on the CRAN website at cran.r-project.org with useful information, including who developed the package, what the latest version is, and when it was last updated (see cran.r-project.org/package=stats19). More importantly, being ‘on CRAN’ (which technically means ‘available on the Comprehensive R Archive Network’) means that it can be installed with the command install.packages() as follows:\n\ninstall.packages(\"stats19\")\n\nYou might think that now that the package has been installed we can start using it, but that is not true. This is illustrated in the code below, which tries and fails to run the find_file_name() function from the stats19 package to find the file containing STATS19 casualties data for the year 2020. Check that this function exists by running the following command ?find_file_name:\n\nfind_file_name(years = 2020, type = \"casualties\")\n\nError in find_file_name(years = 2020, type = \"casualties\"): could not find function \"find_file_name\"",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>R packages</span>"
    ]
  },
  {
    "objectID": "04-pkgs.html#loading-packages",
    "href": "04-pkgs.html#loading-packages",
    "title": "4  R packages",
    "section": "4.4 Loading packages",
    "text": "4.4 Loading packages\nAfter you have installed a package the next step is to ‘load’ it. Load the stats19 package, that was installed in the previous section, using the following code:\n\nlibrary(stats19)\n\nData provided under OGL v3.0. Cite the source and link to:\nwww.nationalarchives.gov.uk/doc/open-government-licence/version/3/\n\n\nWhat happened? Other than the message telling us about the package’s datasets (most packages load silently, so do not worry if nothing happens when you load a package), the command above made the functions and datasets in the package available to us. Now we can use functions from the package without an error message, as follows:\n\nfind_file_name(years = 2020, type = \"casualties\")\n\nNo files of that type found for that year.\n\n\n[1] \"dft-road-casualty-statistics-casualty-2020.csv\" \n[2] \"dft-road-casualty-statistics-vehicle-2020.csv\"  \n[3] \"dft-road-casualty-statistics-collision-2020.csv\"\n\n\nThis raises the question: how do you know which functions are available in a particular package? You can find out using the autocompletion, i.e. by pressing Tab after typing the package’s name, followed by two colons. Try typing stats19:: and then hitting Tab, for example. You should see a load of function names appear, which you view by pressing Up and Down on your keyboard.\nThe final thing to say about packages is that they can be used without being loaded by typing package::function(). We used this before in Section 2.8, where we imported csv data using the readr package via readr::read_csv().\nSo stats19::find_file_name(years = 2020, type = \"casualties\") works even if the package isn’t loaded.\nYou can test this by running the sf_extSoftVersion() command from the sf package. This command reports the versions of key geographic libraries installed on your system. In the first attempt below, the command fails and reports an error. In the second and third attempts, utilising :: and library, you can see that the command succeeds:\n\n# try running a function without loading the sf package first\nsf_extSoftVersion()\n\nError in sf_extSoftVersion(): could not find function \"sf_extSoftVersion\"\n\n\n\n# run a function from a package's namespace without loading it but using ::\nsf::sf_extSoftVersion()\n\n          GEOS           GDAL         proj.4 GDAL_with_GEOS     USE_PROJ_H \n      \"3.12.1\"        \"3.8.4\"        \"9.4.0\"         \"true\"         \"true\" \n          PROJ \n       \"9.4.0\" \n\n\n\n# fun a function call after loading the package (the most common way)\nlibrary(sf)\n\nLinking to GEOS 3.12.1, GDAL 3.8.4, PROJ 9.4.0; sf_use_s2() is TRUE\n\nsf_extSoftVersion()\n\n          GEOS           GDAL         proj.4 GDAL_with_GEOS     USE_PROJ_H \n      \"3.12.1\"        \"3.8.4\"        \"9.4.0\"         \"true\"         \"true\" \n          PROJ \n       \"9.4.0\" \n\n\nAs a bonus, try running the command sf::sf_extSoftVersion without the brackets (). What does that tell you about the package?",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>R packages</span>"
    ]
  },
  {
    "objectID": "04-pkgs.html#using-packages",
    "href": "04-pkgs.html#using-packages",
    "title": "4  R packages",
    "section": "4.5 Using packages",
    "text": "4.5 Using packages\nAfter loading a package, as described in the previous section, you can start using its functions. In the stats19 package that means the following command get_stats19() will now work:\n\ncrashes_2020 = get_stats19(year = 2020, type = \"accidents\")\nnrow(crashes_2020)\n\n[1] 91199\n\n\nThis command demonstrates the value of packages. It would have been possible to get the same dataset by manually downloading and cleaning the file from the STATS19 website on data.gov.uk. However, by using the package, the process has been achieved much faster and with fewer lines of code than would have been possible using general-purpose base R functions. The result of the nrow() function call shows that we have downloaded a decent amount of data representing over 100k road traffic casualty incidents across Great Britain in 2020.\nWe will use other functions from the package in subsequent sections of this guide. If you would like to learn more about stats19 and how it can be used for road safety research, check out its vignettes. The stats19 vignette, for example, should appear in the Help panel in the bottom right panel in RStudio after running the following command:\n\nvignette(\"stats19\")",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>R packages</span>"
    ]
  },
  {
    "objectID": "04-pkgs.html#updating-packages",
    "href": "04-pkgs.html#updating-packages",
    "title": "4  R packages",
    "section": "4.6 Updating packages",
    "text": "4.6 Updating packages\nPackages can be updated with the command update.package() or in ‘Tools &gt; Check for Package Updates’ in RStudio. You only need to install a package once but packages can be updated many times. It is important to update packages regularly because updates will offer bug-fixes and other improvements. To update just one package, you can give the function a package name, e.g.:\n\nupdate.packages(oldPkgs = \"stats19\")\n\nCompleting the following short exercises will ensure you’ve got a good understanding of packages and package versions.\n\nTake a look in the ‘Packages’ tab in the ‘Files’ pane in RStudio (bottom right by default).\nWhat version of the stats19 package is installed on your computer?\nWhat happens the second time you run update.packages(). Why?",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>R packages</span>"
    ]
  },
  {
    "objectID": "04-pkgs.html#ggplot2",
    "href": "04-pkgs.html#ggplot2",
    "title": "4  R packages",
    "section": "4.7 ggplot2",
    "text": "4.7 ggplot2\nggplot2 is a generic plotting package that is part of the ‘tidyverse’ meta-package. The tidyverse is an ‘Opinionated collection of R packages designed for data science’. ggplot2 is flexible, popular and has dozens of add-on packages which build on it, such as gganimate. To plot non-spatial data, it works as follows (the command should generate the image shown in Figure 4.1, showing a bar chart of the number of crashes over time):\n\nlibrary(ggplot2)\nggplot(crashes_2020) + geom_bar(aes(date), width = 1)\n\n\n\n\n\n\n\nFigure 4.1: A simple ggplot2 graph.\n\n\n\n\n\nA key feature of the ggplot2 package is the function ggplot2(). This function initiates the creation of a plot by taking a data object as its main argument followed by one or more ‘geoms’ that represent layers (in this case a bar chart represented by the function geom_bar()). Another distinctive feature of ggplot2() is the use of + operator to add layers.\nThe package is excellent for generating publication quality figures. Starting from a basic idea, you can make incremental tweaks to a plot to get the output you want. Building on the figure above, we could make the bin width (width of the bars) wider, add colour depending on the crash severity and use count (Figure 4.2) or proportion (Figure 4.3) as our y axis, for example, as follows:\nggplot(crashes_2020) + geom_bar(aes(date, fill = accident_severity), width = 1)\nggplot(crashes_2020) +\n  geom_bar(aes(date, fill = accident_severity), width = 1, position = \"fill\") +\n  ylab(\"Proportion of crashes\")\n\n\n\n\n\n\n\n\n\nFigure 4.2: Demonstration of fill and position arguments in ggplot2.\n\n\n\n\n\n\n\n\n\n\n\nFigure 4.3: Demonstration of fill and position arguments in ggplot2.\n\n\n\n\n\n\nThe package is huge and powerful, with support for a very wide range of plot types and themes, so it is worth taking time to read the documentation associated with the package, starting with the online reference manual and heading towards the online version of the package’s official book. As a final taught bit of ggplot2 code in this section, create a facetted plot showing how the number of crashes per hour varies across the days of the week by typing the following into the Source Editor and running the chunk line-by-line (the meaning of the commands should become clear by the end of the next section):\n\nlibrary(tidyverse)\ncrashes_2020 %&gt;% \n  mutate(hour = lubridate::hour(datetime)) %&gt;% \n  mutate(day = lubridate::wday(date)) %&gt;% \n  filter(!is.na(hour)) %&gt;% \n  ggplot(aes(hour, fill = accident_severity)) +\n  geom_bar(width = 1.01) +\n  facet_wrap(~day)\n\n\n\n\n\n\n\nFigure 4.4: A plot showing a facetted time series plot made with ggplot2.\n\n\n\n\n\nExercises: 1. Install a package that build on ggplot2 that begins with with gg. Hint: enter install.packages(gg) and hit Tab when your cursor is between the g and the ). 2. Open a help page in the newly installed package with the ?package_name::function() syntax. 3. Load the package. 4. Bonus: try using functionality from the new ‘gg’ package building on the example above to create plots like those shown below (Hint: the right plot below uses the economist theme from the ggthemes package; try other themes).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>R packages</span>"
    ]
  },
  {
    "objectID": "04-pkgs.html#dplyr",
    "href": "04-pkgs.html#dplyr",
    "title": "4  R packages",
    "section": "4.8 dplyr",
    "text": "4.8 dplyr\nAnother useful package in the tidyverse is dplyr, which stands for ‘data pliers’, which provides a handy syntax for data manipulation. dplyr has many functions for manipulating data frames and using the pipe operator %&gt;%. The pipe operator puts the output of one command into the first argument of the next, as shown below (Note: the results are the same):\n\nlibrary(dplyr)\nclass(crashes_2020)       \n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\ncrashes_2020 %&gt;% class()\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\n\nWe will learn more about this package and its other functions in Section 5.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>R packages</span>"
    ]
  },
  {
    "objectID": "05-data.html",
    "href": "05-data.html",
    "title": "5  Manipulating data",
    "section": "",
    "text": "5.1 tibbles\nThis section is an introduction to manipulating datasets using the dplyr package. As outlined in the previous section, dplyr and ggplot2 are part of the tidyverse, which aims to provide a user-friendly framework for data science.\nExperience of teaching R over the past few years suggests that many people find it easier to get going with data driven research if they learn the ‘tidy’ workflow presented in this section. However, if you do not like this style of R code or you are simply curious, we encourage you to try alternative approaches for achieving the similar results using base R, the data.table R package or other languages such as Python or Julia. If you just want to get going with processing data, the tidyverse is a solid and popular starting point.\nBefore diving into the tidyverse, it is worth re-capping where we have got to so far as we have covered a lot of ground. Section 2 introduced R’s basic syntax; Section 3 showed how to use the Source Editor and other features of RStudio to support data science; and Section 4 introduced the concept and practicalities of R packages, with reference to stats19, ggplot2 and dplyr.\nIn this section, we will start with a blank slate. In Section 2 we learned that in R having a ‘clear desk’ means an empty global environment. This can be achieved by running the following command, which removes the list() of all objects returned by the function ls():\nAlthough the data processing techniques in R are capable of handling large datasets, such as the crashes_2023 object that we created in the previous section, representing 100k+ casualties, it makes sense to start small. Let’s start by re-creating the crashes dataset from Section 2, but this time using the tidyverse tibble() function. This is the tidyverse equivalent of base R’s data.frame. tibble objects can be created, after loading the tidyverse, as follows:\nlibrary(tidyverse)\ncrashes = tibble(\n  casualty_type = c(\"pedestrian\", \"cyclist\", \"cat\"),\n  casualty_age = seq(from = 20, to = 60, by = 20),\n  vehicle_type = c(\"car\", \"bus\", \"tank\"),\n  dark = c(TRUE, FALSE, TRUE)\n)\nIn the previous code chunk, we passed four vector objects as named arguments to the tibble function, resulting in columns such as casualty_type. A tibble is just a fancy way of representing data.frame objects, preferred by tidyverse users and optimised for data science. It has a few sensible defaults and advantages compared with the data.frame, one of which can be seen by printing a tibble:\nclass(crashes)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\ncrashes\n\n# A tibble: 3 × 4\n  casualty_type casualty_age vehicle_type dark \n  &lt;chr&gt;                &lt;dbl&gt; &lt;chr&gt;        &lt;lgl&gt;\n1 pedestrian              20 car          TRUE \n2 cyclist                 40 bus          FALSE\n3 cat                     60 tank         TRUE\nNote the &lt;chr&gt;, &lt;dbl&gt; or &lt;lgl&gt; text below each column, providing a quick indication of the class of each variable - this is not provided when using data.frame.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Manipulating data</span>"
    ]
  },
  {
    "objectID": "05-data.html#filter-and-select-rows-and-columns",
    "href": "05-data.html#filter-and-select-rows-and-columns",
    "title": "5  Manipulating data",
    "section": "5.2 filter() and select() rows and columns",
    "text": "5.2 filter() and select() rows and columns\nIn the previous section, we briefly introduced the package dplyr, which provides an alternative to base R for manipulating objects. dplyr provides different, and some would argue simpler, approaches for subsetting rows and columns than base R.\ndplyr operations for subsetting rows (with the function filter()) and columns (with the function select()) are demonstrated below. Here we can also see the use of the pipe operator %&gt;% to take the dataset and apply the function to that dataset.\n\ncrashes %&gt;% filter(casualty_age &gt; 50) # filters rows\n\n# A tibble: 1 × 4\n  casualty_type casualty_age vehicle_type dark \n  &lt;chr&gt;                &lt;dbl&gt; &lt;chr&gt;        &lt;lgl&gt;\n1 cat                     60 tank         TRUE \n\ncrashes %&gt;% select(casualty_type) # select just one column\n\n# A tibble: 3 × 1\n  casualty_type\n  &lt;chr&gt;        \n1 pedestrian   \n2 cyclist      \n3 cat          \n\n\nIt should be clear what happened: filter() returns only rows that match the criteria in the function call, only observations with a casualty_age greater than 50 in this case. Likewise, select() returns data objects that include only columns named inside the function call, casualty_type in this case.\nTo gain a greater understanding of the functions, type and run the following commands, which also illustrate how the %&gt;% can be used more than once to manipulate data (more on this soon):\n\ncrashes_darkness = crashes %&gt;% filter(dark)\ncrashes_a = crashes %&gt;% select(contains(\"a\"))\ncrashes_darkness_a = crashes %&gt;% \n  filter(dark) %&gt;% \n  select(contains(\"a\"))\n\nCan you guess what the dimensions of the resulting objects will be? Write down your guesses for the number of rows and number of columns that the new objects, crashes_darkness to crashes_darkness_a, have before running the following commands to find out. This also demonstrates the handy function dim(), short for dimension (results not shown):\n\ndim(crashes)\ndim(crashes_darkness)\n?contains # get help on contains() to help guess the output of the next line\ndim(crashes_a)\ndim(crashes_darkness_a)\n\nLook at the help pages associated with filter(), select() and the related function slice() as follows and try running the examples that you will find at the bottom of the help pages for each to gain a greater understanding (note you can use the package::function notation to get help on functions also):\n\n?dplyr::filter\n?dplyr::select\n?dplyr::slice",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Manipulating data</span>"
    ]
  },
  {
    "objectID": "05-data.html#ordering-and-selecting-the-top-n",
    "href": "05-data.html#ordering-and-selecting-the-top-n",
    "title": "5  Manipulating data",
    "section": "5.3 Ordering and selecting the ‘top n’",
    "text": "5.3 Ordering and selecting the ‘top n’\nOther useful pipe-friendly functions are arrange() and top_n(). arrange() can be used to sort data. Within. the arrage() function, optional arguments can be used to define the order in which it is sorted. top_n()simply selects the top ‘n’ number of rows in your data frame. We can use these functions to arrange datasets and take the top most ‘n’ values, as follows:\n\ncrashes %&gt;% \n  arrange(vehicle_type)\n\n# A tibble: 3 × 4\n  casualty_type casualty_age vehicle_type dark \n  &lt;chr&gt;                &lt;dbl&gt; &lt;chr&gt;        &lt;lgl&gt;\n1 cyclist                 40 bus          FALSE\n2 pedestrian              20 car          TRUE \n3 cat                     60 tank         TRUE \n\ncrashes %&gt;% \n  top_n(n = 1, wt = casualty_age)\n\n# A tibble: 1 × 4\n  casualty_type casualty_age vehicle_type dark \n  &lt;chr&gt;                &lt;dbl&gt; &lt;chr&gt;        &lt;lgl&gt;\n1 cat                     60 tank         TRUE",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Manipulating data</span>"
    ]
  },
  {
    "objectID": "05-data.html#summarise",
    "href": "05-data.html#summarise",
    "title": "5  Manipulating data",
    "section": "5.4 Summarise",
    "text": "5.4 Summarise\nA powerful two-function combination is group_by() and summarise(). Used together, they can provide grouped summaries of datasets. In the example below, we find the mean age of casualties in dark and light conditions.\n\ncrashes %&gt;%\n  group_by(dark) %&gt;% \n  summarise(mean_age = mean(casualty_age))\n\n# A tibble: 2 × 2\n  dark  mean_age\n  &lt;lgl&gt;    &lt;dbl&gt;\n1 FALSE       40\n2 TRUE        40\n\n\nThe example above shows a powerful feature of these pipelines. Many operations can be ‘chained’ together, whilst keeping readability with subsequent commands stacked below earlier operations. The combination of group_by() and summarise() can be very useful in preparing data for visualisation with a ggplot2 function. Another useful feature of the tidyverse from a user perspective is the autocompletion of column names mid pipe. If you have not noticed this already, you can test it by typing the following, putting your cursor just before the ) and pressing Tab:\n\ncrashes %&gt;% select(ca) # press Tab when your cursor is just after the a\n\nYou should see casualty_age and casualty_type pop up as options that can be selected by pressing Up and Down. This may not seem like much, but when analysing large datasets with dozens of variables, it can be a godsend.\nRather than providing a comprehensive introduction to the tidyverse suite of packages, this section should have offered enough to get started with using it for road safety data analysis. For further information, check out up-to-date online courses from respected organisations like Data Carpentry and the free online books such as R for Data Science.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Manipulating data</span>"
    ]
  },
  {
    "objectID": "05-data.html#tidyverse-exercises",
    "href": "05-data.html#tidyverse-exercises",
    "title": "5  Manipulating data",
    "section": "5.5 Tidyverse exercises",
    "text": "5.5 Tidyverse exercises\n\nUse dplyr to filter rows in which casualty_age is less than 18, and then 28.\nUse the arrange function to sort the crashes object in descending order of age (Hint: see the ?arrange help page).\nRead the help page of dplyr::mutate(). What does the function do?\nUse the mutate function to create a new variable, birth_year, in the crashes data.frame which is defined as the current year minus their age.\nBonus: Use the %&gt;% operator to filter the output from the previous exercise so that only observations with birth_year after 1969 are returned.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Manipulating data</span>"
    ]
  },
  {
    "objectID": "06-time.html",
    "href": "06-time.html",
    "title": "6  Temporal data",
    "section": "",
    "text": "6.1 Temporal analysis of crash data\nTime is ubiquitous in road safety data, since collisions and road safety implementations always happen at some point in time. This section will show how you can analyse the temporal dimensions of the real world crashes_2021 object we created in Section 4, and then demonstrate how to handle time series data in base R, as well as with hms and lubridate packages. The aim is to get you up-to-speed with how data analysis with time data ‘feels’ before learning the details in subsequent sections. If you are the kind of person who likes to know the details first, feel free to skip this section and return to it later.\nTo get a feel for temporal data analysis in R, let’s start by reading-in crash data for 2021 with the stats19 package by typing the following into the Source Editor and running the code, line-by-line, as taught in Section 3:\nlibrary(stats19)\ncrashes_2021 = get_stats19(2021)\nNote that, unlike the longer crashes_2021 = get_stats19(year = 2021, type = \"accidents\") used in Section 4, we did not use named arguments in this code chunk. Instead of year = 2021, we simply typed 2021. That is possible because R functions can be specified by name matching or order: the first argument of get_stats() is year, so the function is expecting a year value. Also, although we didn’t explicitly specify the accidents table, type = \"accidents\" is the default value, so type only needs to be specified when importing casualty and vehicle datasets.\nWith that educational aside out of the way, we will now take a look at the time variables that are actually in our newly read-in dataset:\nlibrary(tidyverse)\ncrashes_2021 %&gt;% \n  select(matches(\"time|date\")) %&gt;% \n  names()\n\n[1] \"date\"     \"time\"     \"datetime\"\nBuilding on the previous section and a bit of guesswork, it should be clear what just happened: we selected variables that match (with the matches() function) the character strings \"time\" or (as indicated by the | vertical pipe symbol) \"date\" and returned the matching variable names. This shows that the stats19 package gives you not one, not two, but three temporal variables.\nExercises:\nOf the three time variables, it should be clear from the outcome of previous exercises that datetime contains the most useful information. To consolidate the plotting know-how learned in Section 4, we shall start by simply plotting the datetime object (Figure 6.1). Plotting data is a good way of understanding new datasets and the variables they contain. Create the following three plots to show how date and time vary as a function of datetime:\nFigure 6.1: Three plots of the datetime (x axis) in relation to the date and time axis.\n\n\n\n\n\n\n\n\n\n\n\nFigure 6.2: Three plots of the datetime (x axis) in relation to the date and time axis.\n\n\n\n\n\n\n\n\n\n\n\nFigure 6.3: Three plots of the datetime (x axis) in relation to the date and time axis.\nThe three figures above tell us many things about the contents of the three temporal variables. It evenprovides insight into the temporal distribution of road casualties in Great Britain. The first two plots (Figure 6.1 and 6.2) show: 1) that the date variable is identical to the datetime variable (at least on the daily resolution than can be seen on the graph); and 2) that time values repeat regularly for the range of dates in datetime (from the start of Jan 2021 to end of Dec 2021). Figure 6.3 makes use of ggplot2‘s functionality to show only certain labels on the Y axis and reduced opacity, so that overlapping points are not completely black. This by far is the most useful of the three plots, showing that most crashes happen between around 7am and 7pm, with a ’long tail’ of crashes in the evening, and that for most of the year there is a clear weekly cycle, reflecting the uptick in crashes during the rush hour commute on weekdays, a pattern that is greatly diminished during several weeks in summer (perhaps corresponding with summer holidays). The 52 weeks of the year can be distinguished even in this small and simple plot, highlighting the ability of visualisation to help understand data. Next, let’s look at how the time-of-day that crashes occur varies as a function of season, severity and day of week.\nFrom the datetime object of class POSIXct, any type of time information can be extracted. This includes the minute, hour, day of week and month of the crash (or other) event that the object records.\nBuilding on the time series plot we created in Section 4, let’s create a graph showing how the hourly distribution of crash numbers changes during the course of a working week. We will do this first by preprocessing the data, creating a new object called crashes_dow, containing hour and day columns, then filtering out weekend, and plotting the results, as shown in the code chunk below and Figure 6.4:\n# days of the week:\ndow = c(\"Sunday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\")\ncrashes_dow = crashes_2021 %&gt;% \n  mutate(hour = lubridate::hour(datetime)) %&gt;% \n  mutate(day = factor(weekdays(date), levels = dow)) \n\ncrashes_dow %&gt;% \n  filter(!is.na(hour) & !day %in% c(\"Saturday\", \"Sunday\")) %&gt;% \n  ggplot(aes(hour)) +\n  geom_bar(width = 1.01) +\n  facet_wrap(~day, nrow = 1)\n\n\n\n\n\n\n\nFigure 6.4: Facetted time series showing how the number of crashes increases during the working week.\nThe result in Figure 6.4 is useful, but if we’re interested in the number of crashes per hour on different days of the week relative to the average, we need to undertake more preprocessing steps. We will count the number of crashes per hour for all 5 working days and then divide by 5 to get the average number of crashes per hour during weekdays. Then we will count the number of crashes per hour/week combination. Finally we will divide the latter by the former. These steps are shown in the code chunk below, which results in Figure 6.5.\ncrashes_day_rel = crashes_dow %&gt;%  # create 'day of week relative' object  \n  filter(!is.na(hour) & !day %in% c(\"Saturday\", \"Sunday\")) %&gt;% # none on weekends\n  select(day, hour) %&gt;%            # keep only time columns\n  group_by(hour) %&gt;%               # group by hour\n  mutate(n_per_hour = n()/5) %&gt;%   # number per hour (divide by 5 for n. days)\n  group_by(day, hour) %&gt;%          # group by day and hour\n  summarise(n_hday = n(), n_h = first(n_per_hour)) %&gt;% # summarise results\n  mutate(hday_relative = n_hday / n_h) # calculate relative n. crashes per hour/day\nsummary(crashes_day_rel)\n\n        day          hour           n_hday            n_h        \n Sunday   : 0   Min.   : 0.00   Min.   :  54.0   Min.   :  63.6  \n Monday   :24   1st Qu.: 5.75   1st Qu.: 195.5   1st Qu.: 252.2  \n Tuesday  :24   Median :11.50   Median : 662.5   Median : 657.3  \n Wednesday:24   Mean   :11.50   Mean   : 630.2   Mean   : 630.2  \n Thursday :24   3rd Qu.:17.25   3rd Qu.: 952.8   3rd Qu.: 899.1  \n Friday   :24   Max.   :23.00   Max.   :1510.0   Max.   :1397.2  \n Saturday : 0                                                    \n hday_relative   \n Min.   :0.7087  \n 1st Qu.:0.9309  \n Median :0.9869  \n Mean   :1.0000  \n 3rd Qu.:1.0440  \n Max.   :1.6220  \n                 \n\ncrashes_day_rel %&gt;% \n  ggplot() +\n  geom_col(aes(hour, hday_relative)) +\n  facet_wrap(~day, nrow = 1)\n\n\n\n\n\n\n\nFigure 6.5: Facetted time series showing relative number of crashes per hour by day in the working week.\nThe results clearly show that Friday is a dangerous day as many of the columns are above 1 (NB as this is a relative calculation, columns that are less than 1 indicate that there are less crashes per hour on that day than average whereas those above 1 indicate that there are more crashes per hour on that day than average). The extent to which the high relative number of crashes in the most anomalous hours (Friday evening) is due increased exposure vs increased risk per km travelled cannot be ascertained by this plot but it certainly suggests that Friday afternoon and evening is a worthy focus of road safety research.\nExercises:",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Temporal data</span>"
    ]
  },
  {
    "objectID": "06-time.html#temporal-analysis-of-crash-data",
    "href": "06-time.html#temporal-analysis-of-crash-data",
    "title": "6  Temporal data",
    "section": "",
    "text": "Print the first 6 and then the first 10 elements of each of the three temporal variables in crashes_2021.\nWhat is the class of each variable (technically, of each vector)?\nBonus: Extract the weekday from the variable called date.\nBonus: How many crashes happened on Monday?\n\n\nlibrary(ggplot2)\nggplot(crashes_2021) + geom_point(aes(datetime, date))\nggplot(crashes_2021) + geom_point(aes(datetime, time))\nb = c(\"07:00\", \"09:00\", \"12:00\", \"17:00\", \"19:00\")\nggplot(crashes_2021) + geom_point(aes(datetime, time), alpha = 0.01) +\n  scale_y_discrete(breaks = b)\n\n\n\n\n\n\n\n\n\n\nBuilding on the code above, show the absolute and relative number of crashes per hour on Saturday and Sunday.\nFilter the dataset so it contains only data from two police forces of your choice (e.g. West Yorkshire and Metropolitan Police).\nTry creating plots similar to those shown above but facetted by police force rather than by day of the week.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Temporal data</span>"
    ]
  },
  {
    "objectID": "06-time.html#handling-dates-and-date-times",
    "href": "06-time.html#handling-dates-and-date-times",
    "title": "6  Temporal data",
    "section": "6.2 Handling dates and date-times",
    "text": "6.2 Handling dates and date-times\nIt is worth remembering that base R already has decent support for dates and datetimes, although the base R functions are not particularly intuitive. This is shown in the code chunk below, which creates objects representing the date and time of a fictitious crash event on a cold winter’s morning, 1st January 2021, and a subsequent road safety intervention on the 20th October 2021:\n\ncrash_datetime_character = \"2021-01-01 08:35\" # creates date/time as a character\ncrash_datetime = as.POSIXct(crash_datetime_character) # converts date/time to a object of the POSIXct type\nclass(crash_datetime)\n\n[1] \"POSIXct\" \"POSIXt\" \n\nintervention_date_character = \"2021-10-20\"\nintervention_date = as.Date(intervention_date_character) # converts date/time to a object of the Date type\nclass(intervention_date)\n\n[1] \"Date\"\n\n# see ?as.POSIXct for more examples\n\n‘POSIXct’, ‘POSIXt’ and ‘Date’ are data types for dates and time that enable easy manipulation of such data. Fortunately for most users, there are easier ways to work with time series data, starting with the hms package.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Temporal data</span>"
    ]
  },
  {
    "objectID": "06-time.html#hours-minutes-seconds-with-hms",
    "href": "06-time.html#hours-minutes-seconds-with-hms",
    "title": "6  Temporal data",
    "section": "6.3 Hours, minutes seconds with hms",
    "text": "6.3 Hours, minutes seconds with hms\nThe hms library in the tidyverse can be used to process hours, minutes and seconds, as shown below. See a very basic demo of the package and links to the package’s help pages with the following commands in which we use the package without loading it with the library() function, demonstrating the package::function() syntax taught in Section 4:\n\nlibrary(tidyverse)\n\n\ncrash_time_character = \"08:35:00\"\ncrash_time_hms = hms::as_hms(crash_time_character)\nclass(crash_time_hms)\n\n[1] \"hms\"      \"difftime\"\n\n\n\n?hms::`hms-package`\n\nAs the package’s name suggests, it is used for dealing with hours, minutes and seconds. It can round time objects of class hms to the nearest second (or any multiple of a second):\n\nhms::round_hms(crash_time_hms, 1)           # time to the nearest second\n\n08:35:00\n\nhms::round_hms(crash_time_hms, 1 * 60 * 60) # time to the nearest hour\n\n09:00:00\n\nhms::round_hms(crash_time_hms, 1 * 30 * 60) # time to the nearest half hour\n\n08:30:00\n\n\nIt can also convert simple text strings into time objects, e.g. as follows (Note: we do not need to include the :00):\n\nhms::parse_hm(\"08:35\")\n\n08:35:00",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Temporal data</span>"
    ]
  },
  {
    "objectID": "06-time.html#the-lubridate-package",
    "href": "06-time.html#the-lubridate-package",
    "title": "6  Temporal data",
    "section": "6.4 The lubridate package",
    "text": "6.4 The lubridate package\nIn many cases the most useful and easy to use package when working with temporal data is lubridate. Having installed it, load it as follows:\n\nlibrary(lubridate)\n\nThe simplest example of a Date object that we can analyze is just the current date, i.e.:\n\ntoday()\n\n[1] \"2025-08-30\"\n\n\nWe can manipulate this object using several lubridate functions to extract the current day, month, year, weekday and so on…\n\nx = today()\nday(x)\nwday(x)\nwday(x) %in% c(1, 6) # is it the weekend?\nmonth(x)\nyear(x)\n\nBase R can also be used to extract data e.g. # Base R function to get the day of week weekdays(x).\nExercises: \n\nLook at the help page of the lubridate function month to see how it is possible to extract the current month as a character vector.\nLook at other functions in lubridate to extract the current weekday as a number, the week of year and the day of the year.\n\nDate variables are often stored simply as character vectors. This is a problem, since R is not always smart enough to distinguish between character vectors representing Dates. lubridate provides functions that can translate a wide range of date encodings such as ymd(), which extracts the Year, Month and Day from a character string, as demonstrated below.\n\nas.Date(\"2021-10-17\") # works\nas.Date(\"2021 10 17\") # fails\nymd(\"2021 10 17\")     # works\ndmy(\"17/10/2021\")     # works\n\nImport functions, such as read_csv, try to recognize the Date variables. Sometimes this fails. You can manually create Date objects, as shown below:\n\nx = c(\"2009-01-01\", \"2009-02-02\", \"2009-03-03\")\nx_date = ymd(x)\nx_date\n\n[1] \"2009-01-01\" \"2009-02-02\" \"2009-03-03\"\n\n\nExercises:\n\nExtract the day, the year-day, the month and the weekday (as a non-abbreviated character vector) of each element of x_date.\nConvert \"09/09/93\" into a date object and extract its weekday.\nBonus: Read the help page of as.Date and strptime for further details on base R functions for dates.\nBonus: Read the Chapter 16 of R for Data Science book for further details on lubridate package.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Temporal data</span>"
    ]
  },
  {
    "objectID": "06-time.html#dates-in-a-data-frame",
    "href": "06-time.html#dates-in-a-data-frame",
    "title": "6  Temporal data",
    "section": "6.5 Dates in a data frame",
    "text": "6.5 Dates in a data frame\nWe can use Dates for subsetting events in a dataframe. For example, if we define x_date as before and add it to the crash dataset, i.e.:\n\ncrashes$casualty_day = x_date\n\nThen we can subset events using Dates. For example:\n\nfilter(crashes, day(casualty_day) &lt; 7) # the events that ocurred in the first week of the month\n\n# A tibble: 3 × 5\n  casualty_type casualty_age vehicle_type dark  casualty_day\n  &lt;chr&gt;                &lt;dbl&gt; &lt;chr&gt;        &lt;lgl&gt; &lt;date&gt;      \n1 pedestrian              20 car          TRUE  2009-01-01  \n2 cyclist                 40 bus          FALSE 2009-02-02  \n3 cat                     60 tank         TRUE  2009-03-03  \n\nfilter(crashes, weekdays(casualty_day) == \"Monday\") # the events occurred on monday\n\n# A tibble: 1 × 5\n  casualty_type casualty_age vehicle_type dark  casualty_day\n  &lt;chr&gt;                &lt;dbl&gt; &lt;chr&gt;        &lt;lgl&gt; &lt;date&gt;      \n1 cyclist                 40 bus          FALSE 2009-02-02  \n\n\nExercises:\n\nSelect only the events (rows in crashes) that occurred in January.\nSelect only the events that ocurred in an odd year-day.\nSelect only the events that ocurred in a leap-year (Hint: check the function leap_year).\nSelect only the events that ocurred during the weekend or in June.\nSelect only the events that ocurred during the weekend and in June.\nCount how many events ocurred during each day of the week.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Temporal data</span>"
    ]
  },
  {
    "objectID": "06-time.html#components-of-time-objects",
    "href": "06-time.html#components-of-time-objects",
    "title": "6  Temporal data",
    "section": "6.6 Components of time objects",
    "text": "6.6 Components of time objects\nNow we’ll take a look at the time components of a Date. Using the function hms (acronym for Hour, Minutes, Seconds) and its subfunctions such as hm or ms, we can parse a character vector representing several times into an Hour object (which is technically called a ‘period object’).\n\nx = c(\"18:23:35\", \"00:00:01\", \"12:34:56\")\nx_hour = hms(x)\nx_hour\n\n[1] \"18H 23M 35S\" \"1S\"          \"12H 34M 56S\"\n\n\nWe can manipulate these objects using several lubridate functions to extract the hour component, the minutes, and so on:\n\nhour(x_hour)\n\n[1] 18  0 12\n\nminute(x_hour)\n\n[1] 23  0 34\n\nsecond(x_hour)\n\n[1] 35  1 56\n\n\nIf the Hour data does not specify the seconds, we just use a subfunction of hms, namely hm, to get the hours and minutes, rather than hours, minutes and seconds.\n\nx = c(\"18:23\", \"00:00\", \"12:34\")\n(x_hour = hm(x))\n\n[1] \"18H 23M 0S\" \"0S\"         \"12H 34M 0S\"\n\n\nWe can use Hour data also for subsetting events, like we did for Dates. Let’s add a new column for hour to the crashes data:\n\ncrashes$casualty_hms = hms(c(\"18:23:35\", \"00:00:01\", \"12:34:56\"))\ncrashes$casualty_hour = hour(crashes$casualty_hms)\n\nExercises:\n\nFilter only the events that occurred after midday (i.e. the PM events). Hint: your answer may include &gt;= 12.\nFilter only the events that ocurred between 15:00 and 19:00.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Temporal data</span>"
    ]
  },
  {
    "objectID": "07-space.html",
    "href": "07-space.html",
    "title": "7  Spatial data",
    "section": "",
    "text": "7.1 sf objects\nFrom displaying simple point data to examining collision density along routes or between areas, the geographic property of STATS19 data is one of its most useful attributes. Mapping is a hugely useful and powerful aspect of R and has many applications in road safety, both in understanding geographic trends and presenting insight to colleagues. This aspect of R is covered in detail in the book Geocomputation With R. By mapping collision data in R, you can add layers containing other geographic datasets to further understand the reasons for certain trends. This can lead to new opportunities for intervention and collaboration with other parties who may have mutually compatible solutions for reaching their goals. We will use the following packages in this section:\nAll road crashes happen somewhere and, in the UK at least, all collisions recorded by the police are given geographic coordinates. These can help in prioritising interventions to save lives by focusing on ‘crash hotspots.’ R has strong geographic data capabilities with the sf package, providing a generic class for spatial vector data. Points, lines and polygons are represented in sf as objects in a special ‘geometry column’, typically called ‘geom’ or ‘geometry’, extending the data frame class we’ve already seen in crashes, created in Section 5 (repeated here to consolidate data frame creation):\ncrashes = tibble(\n  casualty_type = c(\"pedestrian\", \"cyclist\", \"cat\"),\n  casualty_age = seq(from = 20, to = 60, by = 20),\n  vehicle_type = c(\"car\", \"bus\", \"tank\"),\n  dark = c(TRUE, FALSE, TRUE)\n)\nCreate an sf data frame called crashes_sf that expands the crashes data frame to include a geometry column based on the crashes longitude and latitude data as follows:\ncrashes_sf = crashes # create copy of crashes dataset\ncrashes_sf$longitude = c(-1.3, -1.2, -1.1)\ncrashes_sf$latitude = c(50.7, 50.7, 50.68)\ncrashes_sf = st_as_sf(crashes_sf, coords = c(\"longitude\", \"latitude\"), crs = 4326) # st_as_sf converts longitude and latitude coordinates into spatial objects using a specified Coordinate Reference System (see 7.6)\nExercises:\nFigure 7.1: The crashes_sf dataset shown in map form with the function plot().\n\n\n\n\n\n\n\n\n\n\n\nFigure 7.2: The crashes_sf dataset shown in map form with the function plot().\n\n\n\n\n\n\n\n\n\n\n\nFigure 7.3: The crashes_sf dataset shown in map form with the function plot().",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Spatial data</span>"
    ]
  },
  {
    "objectID": "07-space.html#sf-objects",
    "href": "07-space.html#sf-objects",
    "title": "7  Spatial data",
    "section": "",
    "text": "Plot only the geometry column of crashes_sf (Hint: the solution may contain $geometry). If the result is like that in Figure 7.1, congratulations, it worked!\nPlot crashes_sf, only showing the age variable.\nPlot the 2nd and 3rd crashes, showing which happened in the dark.\nBonus: How far apart are the points? (Hint: sf functions begin with st_)\nBonus: Near which settlement did the tank runover the cat?\n\nplot(crashes_sf$geometry)\nplot(crashes_sf[\"casualty_age\"])\nplot(crashes_sf[2:3, \"dark\"])",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Spatial data</span>"
    ]
  },
  {
    "objectID": "07-space.html#reading-and-writing-spatial-data",
    "href": "07-space.html#reading-and-writing-spatial-data",
    "title": "7  Spatial data",
    "section": "7.2 Reading and writing spatial data",
    "text": "7.2 Reading and writing spatial data\nYou can read and write spatial data with read_sf() and write_sf(), as shown below (see ?read_sf):\nFirst, let’s create the zones object that we’ll use for demonstration:\n\nzones = pct::get_pct_zones(\"isle-of-wight\")[1:9]\n\nNow we can read and write spatial data:\n\nwrite_sf(zones, \"zones.geojson\") # saves the spatial dataset called zones as geojson file type\nwrite_sf(zones, \"zmapinfo\", driver = \"MapInfo file\") # saves the dataset as a MapInfo file\nread_sf(\"zmapinfo\") # reads-in mapinfo file\n\nSee Chapter 6 of Geocomputation with R for further information.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Spatial data</span>"
    ]
  },
  {
    "objectID": "07-space.html#sf-polygons",
    "href": "07-space.html#sf-polygons",
    "title": "7  Spatial data",
    "section": "7.3 sf polygons",
    "text": "7.3 sf polygons\nsf objects can also represent administrative zones. This is illustrated below with reference to zones, a spatial object representing the Isle of Wight, that we created in the previous section. Exercises:\n\nWhat is the class of the zones object?\nWhat are its column names?\nPrint its first 2 rows and columns 6:8 (the result is below).\n\n\n\nSimple feature collection with 2 features and 5 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -1.301131 ymin: 50.69052 xmax: -1.28837 ymax: 50.70547\nGeodetic CRS:  WGS 84\n# A tibble: 2 × 6\n  geo_code    all bicycle  foot car_driver                              geometry\n  &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;                    &lt;MULTIPOLYGON [°]&gt;\n1 E01017326   698      23   285        286 (((-1.289993 50.69766, -1.290177 50.…\n2 E01017327   720      25   225        374 (((-1.295712 50.69383, -1.29873 50.6…",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Spatial data</span>"
    ]
  },
  {
    "objectID": "07-space.html#spatial-subsetting-and-sf-plotting",
    "href": "07-space.html#spatial-subsetting-and-sf-plotting",
    "title": "7  Spatial data",
    "section": "7.4 Spatial subsetting and sf plotting",
    "text": "7.4 Spatial subsetting and sf plotting\nLike index and value subsetting, spatial subsetting can be done with the [] notation. We can identify the crashes (crashes_sf) that occur in the Isle of Wight (zones) by subsetting as follows (i.e. subset zones by whether it contains data in crashes_sf):\n\nzones_containing_crashes = zones[crashes_sf, ]\n\nTo plot a new layer on top of an existing sf plot, use the add = TRUE argument, e.g. as follows:\n\nplot(zones$geometry) # plot just the geometry of one layer\nplot(zones_containing_crashes$geometry, col = \"grey\", add = TRUE)\n\nRemember to plot only the geometry column of objects to avoid multiple maps. Colours can be set with the col argument.\nExercises:\n\nPlot the geometry of the zones, with the zones containing crashes overlaid on top in red (see Figure 7.4).\nPlot the zone containing the 2nd crash in blue (see Figure 7.5).\nBonus: Plot all zones that intersect with a zone containing crashes, with the actual crash points plotted in black (see Figure 7.6).\n\nplot(zones$geometry)\nplot(zones_containing_crashes$geometry, col = \"red\", add = TRUE)\nplot(zones$geometry)\nplot(zones[crashes_sf[2, ], ], col = \"blue\", add = TRUE)\nplot(zones$geometry)\nplot(zones[zones_containing_crashes, ], col = \"yellow\", add = TRUE)\nplot(crashes_sf$geometry, pch = 20, add = TRUE)\n\n\n\n\n\n\n\n\n\nFigure 7.4: Illustration of the results of spatial subsetting.\n\n\n\n\n\n\n\n\n\n\n\nFigure 7.5: Illustration of the results of spatial subsetting.\n\n\n\n\n\n\n\n\n\n\n\nFigure 7.6: Illustration of the results of spatial subsetting.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Spatial data</span>"
    ]
  },
  {
    "objectID": "07-space.html#geographic-joins",
    "href": "07-space.html#geographic-joins",
    "title": "7  Spatial data",
    "section": "7.5 Geographic joins",
    "text": "7.5 Geographic joins\nGeographic joins involve assigning values from one object to a new column in another, based on the geographic relationship between them. With sf objects, the data from the crashes_sf dataset is joined onto the ‘target’ zones dataset, to create a new object called zones_joined:\n\nzones_joined = st_join(zones[1], crashes_sf)\n\nThe above code takes the geo_code column data from zones, matches it to the geometry column in crashes_sf and then joins it to the crashes that have occurred in those geo_codes. The matched, joined geo_code is a new column in the zone_joined dataset. We now know the administrative geo_code in which each crash occured.\nExercises:\n\nPlot the casualty_age variable of the new zones_joined object (see Figure 7.7, to verify the result).\nHow many zones are returned in the previous command?\nSelect only the geo_code column from the zones and the dark column from crashes_sf and use the left = FALSE argument to return only zones in which crashes occurred. Plot the result. (Hint: it should look like the map shown in Figure 7.8)\n\nSee Chapter 4 of Geocomputation with R for further information on geographic joins.\nplot(zones_joined[\"casualty_age\"])\nzjd = st_join(zones[1], crashes_sf[\"dark\"], left = FALSE)\nplot(zjd)\n\n\n\n\n\n\n\n\n\nFigure 7.7: Illustration of geographic joins.\n\n\n\n\n\n\n\n\n\n\n\nFigure 7.8: Illustration of geographic joins.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Spatial data</span>"
    ]
  },
  {
    "objectID": "07-space.html#coordinate-reference-systems",
    "href": "07-space.html#coordinate-reference-systems",
    "title": "7  Spatial data",
    "section": "7.6 Coordinate Reference Systems",
    "text": "7.6 Coordinate Reference Systems\nA Coordinate Reference Systems (CRS) is used for plotting data on maps. There are many systems in use but they can generally be classified into two groups; ‘projected’ and ‘geographic’. A projected system, such as Eastings/Northings, plots locations onto a flat 2D projection of the Earth’s surface. A geographic system, such as Longitude/Latitude, refers to locations on the 3D surface of the globe. Distance and direction calculations work differently between geographic and projected CRSs, so it is often necessary to convert from one to another. Fortunately, R makes this very easy, and every CRS has its own unique reference number. For example, 27700 for the British National Grid system.\nCRSs define how two-dimensional points (such as longitude and latitude) are actually represented in the real world. A CRS value is needed to interpret and give true meaning to coordinates. You can get and set CRSs with the command st_crs(). Transform CRSs with the command st_transform(), as demonstrated in the code chunk below, which converts the ‘lon/lat’ geographic CRS of crashes_sf into the projected CRS of the British National Grid:\n\ncrashes_osgb = st_transform(crashes_sf, 27700)\n\nExercises:\n\nTry to subset the zones with the crashes_osgb. What does the error message say?\nCreate zones_osgb by transforming the zones object.\nBonus: Use st_crs() to find out the units measurement of the British National Grid.\n\nFor more information on CRSs see Chapter 6 of Geocompuation with R.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Spatial data</span>"
    ]
  },
  {
    "objectID": "07-space.html#buffers",
    "href": "07-space.html#buffers",
    "title": "7  Spatial data",
    "section": "7.7 Buffers",
    "text": "7.7 Buffers\nBuffers are polygons surrounding geometries, usually with fixed distance. For example, in road safety research a 30m buffer can be created around crash locations to identify crashes that happened in close proximity to a particular junction or road segment.\nExercises:\n\nFind out and read the help page of sf’s buffer function.\nCreate an object called crashes_1km_buffer representing the area within 1 km of the crashes_osgb object and plot the result using the command: plot(crashes_1km_buffer). As a fun bonus, try: mapview::mapview(crashes_1km_buffer).\nBonus: Try creating buffers on the geographic version of the crashes_sf object. What happens?",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Spatial data</span>"
    ]
  },
  {
    "objectID": "07-space.html#attribute-operations-on-sf-objects",
    "href": "07-space.html#attribute-operations-on-sf-objects",
    "title": "7  Spatial data",
    "section": "7.8 Attribute operations on sf objects",
    "text": "7.8 Attribute operations on sf objects\nWe can do non-spatial operations on sf objects because they are data.frames. Try the following attribute operations on the zones data:\n\n# use the zones dataset we created earlier\nsel = zones$all &gt; 3000  # create a subsetting object\nzones_large = zones[sel, ] # subset areas with a population over 3,000\nzones_2 = zones[zones$geo_name == \"Isle of Wight 002\",] # subset based on 'equality' query\nzones_first_and_third_column = zones[c(1, 3)]\nzones_just_all = zones[\"all\"]\n\nExercises:\n\nPractice the subsetting techniques you have learned on the sf data.frame object zones:\n\nCreate an object called zones_small, which contains only regions with less than 3000 people in the all column.\nCreate a selection object called sel_high_car which is TRUE for regions with above median numbers of people who travel by car and FALSE otherwise.\nCreate an object called zones_foot which contains only the foot attribute from zones.\nBonus 1: plot zones_foot using the function plot to show where walking is a popular mode of travel to work.\nBonus 2: building on your answers to previous questions, use filter() from the dplyr package to subset small regions where car use is high.\n\nBonus: What is the population density of each region (Hint: you may need to use the functions st_area(), as.numeric() and use the ‘all’ column)?\nBonus: Which zone has the highest percentage of people who cycle?",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Spatial data</span>"
    ]
  },
  {
    "objectID": "07-space.html#mapping-road-crash-data",
    "href": "07-space.html#mapping-road-crash-data",
    "title": "7  Spatial data",
    "section": "7.9 Mapping road crash data",
    "text": "7.9 Mapping road crash data\nSo far we have used the plot() function to make maps. That’s fine for basic visualisation, but for publication-quality maps we recommend using tmap. See Chapter 8 of Geocomputation with R for further explanation and alternatives. After installation, load the package as follows:\n\nlibrary(tmap)\ntmap_mode(\"plot\") # this sets the tmap mode to plotting as opposed to interactive\n\nℹ tmap mode set to \"plot\".\n\n\nExercises:\n\nCreate the plots of the zones object using plot() and tm_shape() + tm_polygons() functions (see Figure 7.9).\nCreate an interactive version of the tmap plot by setting tmap_mode(\"view\") and re-running the plotting commands.\nAdd an additional layer to the interactive map showing the location of crashes, using marker and dot symbols.\nBonus: Change the default basemap (Hint: you may need to search in the package documentation or online for the solution).\n\nplot(zones[c(\"all\", \"bicycle\")])\ntm_shape(zones) + \n  tm_polygons(c(\"all\", \"bicycle\"))\n\n\n\n\n\n\n\n\n\nFigure 7.9: Illustration of the plot and tmap approaches for creating maps.\n\n\n\n\n\n\n\n\n\n\n\nFigure 7.10: Illustration of the plot and tmap approaches for creating maps.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Spatial data</span>"
    ]
  },
  {
    "objectID": "07-space.html#analysing-point-data",
    "href": "07-space.html#analysing-point-data",
    "title": "7  Spatial data",
    "section": "7.10 Analysing point data",
    "text": "7.10 Analysing point data\nBased on the saying, “Don’t run before you can walk,” we’ve learned the vital foundations of R before tackling a real dataset. Temporal and spatial attributes are key to road crash data, hence the emphasis on lubridate and sf. Visualisation is central to understanding data and influencing policy, which is where tmap comes in. With these solid foundations, plus knowledge of how to ask for help (we recommend reading R’s internal help, asking colleagues, searching the internet and creating new questions or comments on online forums such as StackOverflow or GitHub and we suggest you follow this order of resources to get help), you are ready to test the methods on some real data.\nBefore doing so, take a read of the stats19 vignette, which can be launched as follows:\n\nvignette(package = \"stats19\") # view all vignettes available on stats19\nvignette(\"stats19\") # view the introductory vignette\n\nThis should now be sufficient to tackle the following exercises:\n\nDownload and plot all crashes reported in Great Britain in 2023. (Hint: see the stats19 vignette)\nFind the function in the stats19 package that converts a data.frame object into an sf data frame. Use this function to convert the road crashes into an sf object, called crashes_sf, for example.\nFilter crashes that happened in the Isle of Wight based on attribute data. (Hint: the relevant column contains the word local)\nFilter crashes happened in the Isle of Wight using geographic subsetting. (Hint: remember st_crs()?)\nBonus: Which type of subsetting yielded more results and why?\nBonus: How many crashes happened in each zone?\nCreate a new column called month in the crash data using the function lubridate::month() and the date column.\nCreate an object called a_zones_may representing all the crashes that happened in the Isle of Wight in the month of May.\nBonus: Calculate the average (mean) speed limit associated with each crash that happened in May across the zones of the Isle of Wight (the result is shown in the map).\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 7.11: Maps of the Isle of Wight.\n\n\n\n\n\n\n\n\n\n\n\nFigure 7.12: Maps of the Isle of Wight.\n\n\n\n\n\n\n\nremotes::install_github(\"itsleeds/osmextract\") # install github package for osm data\nlibrary(osmextract)\nregion_name = \"essex\" # \"essex\" can be changed to another area name as required\nosm_data = oe_get(region_name, extra_tags = c(\"maxspeed\", \"ref\"))\ntable(osm_data$highway)\n#filter osm_data to show only major roads\nroads = osm_data %&gt;%\n  filter(str_detect(highway, pattern = \"moto|prim|seco|tert|trunk\"))\n# transform geometry and save\nroads = st_transform(roads, 27700) #converts to projected BNG system for later use\n# plot(roads$geometry) # basic plot of roads\ntm_shape(roads) + tm_lines(\"maxspeed\", showNA = T, lwd = 2)\nsaveRDS(roads, file = \"roads.Rds\") # Saves road dataset for future use\n\n\n\n\n\n\n── tmap v3 code detected ───────────────────────────────────────────────────────\n\n\n[v3-&gt;v4] `tm_lines()`: migrate the argument(s) related to the legend of the\nvisual variable `col` namely 'showNA' to 'col.legend = tm_legend(&lt;HERE&gt;)'\n\n\n\n\n\n\n\n\nFigure 7.13: Roads in Essex downloaded with the code shown above.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Spatial data</span>"
    ]
  },
  {
    "objectID": "07-space.html#bonus-exercises",
    "href": "07-space.html#bonus-exercises",
    "title": "7  Spatial data",
    "section": "Bonus exercises",
    "text": "Bonus exercises\nIdentify a region and zonal units of interest from http://geoportal.statistics.gov.uk/ or from the object police_boundaries in the stats19 package.\n\nRead them into R as an sf object.\nCreate a map showing the number of crashes in each zone.\nIdentify the average speed limit associated with crashes in each zone.\nIdentify an interesting question you can ask to the data and use exploratory data analysis to find answers.\nCheck another related project for further information on smoothing techniques of counts on a linear network.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Spatial data</span>"
    ]
  },
  {
    "objectID": "08-join.html",
    "href": "08-join.html",
    "title": "8  Joining road crash tables",
    "section": "",
    "text": "8.1 STATS19 tables\nThus far, we have been working primarily with ‘accident’ level data, but there is much useful data in other tables. As outlined in the stats19 vignette — which you can view by entering the command vignette(\"stats19\") to get extended help pages about R packages — there are three main tables that contain STATS19 data.\nLet’s read-in data from 2023 to take a look:\nlibrary(stats19)\nlibrary(dplyr)\nlibrary(ggplot2)\nac = get_stats19(year = 2023, type = \"accidents\")\nca = get_stats19(year = 2023, type = \"casualties\")\n\nWarning: The following named parsers don't match the column names:\naccident_severity, carriageway_hazards, collision_index, collision_reference,\ncollision_year, date, day_of_week, did_police_officer_attend_scene_of_accident,\ndid_police_officer_attend_scene_of_collision, enhanced_collision_severity,\nfirst_road_class, first_road_number, junction_control, junction_detail,\nlatitude, legacy_collision_severity, light_conditions,\nlocal_authority_district, local_authority_highway,\nlocal_authority_ons_district, location_easting_osgr, location_northing_osgr,\nlongitude, lsoa_of_accident_location, lsoa_of_collision_location,\nnumber_of_casualties, number_of_vehicles, pedestrian_crossing_human_control,\npedestrian_crossing_physical_facilities, police_force, road_surface_conditions,\nroad_type, second_road_class, second_road_number, special_conditions_at_site,\nspeed_limit, time, trunk_road_flag, urban_or_rural_area, weather_conditions,\nadjusted_serious, adjusted_slight, injury_based, accident_ref_no,\neffective_date_of_change, previously_published_value, replacement_value,\nvariable, age_band_of_driver, age_of_driver, age_of_vehicle, dir_from_e,\ndir_from_n, dir_to_e, dir_to_n, driver_distance_banding, driver_home_area_type,\ndriver_imd_decile, engine_capacity_cc, escooter_flag, first_point_of_impact,\ngeneric_make_model, hit_object_in_carriageway, hit_object_off_carriageway,\njourney_purpose_of_driver, junction_location, lsoa_of_driver, propulsion_code,\nsex_of_driver, skidding_and_overturning, towing_and_articulation,\nvehicle_direction_from, vehicle_direction_to, vehicle_leaving_carriageway,\nvehicle_left_hand_drive, vehicle_location_restricted_lane, vehicle_manoeuvre,\nvehicle_type\n\n\nWarning in asMethod(object): NAs introduced by coercion\n\nve = get_stats19(year = 2023, type = \"vehicle\")\n\nWarning: The following named parsers don't match the column names: accident_severity, carriageway_hazards, collision_index, collision_reference, collision_year, date, day_of_week, did_police_officer_attend_scene_of_accident, did_police_officer_attend_scene_of_collision, enhanced_collision_severity, first_road_class, first_road_number, junction_control, junction_detail, latitude, legacy_collision_severity, light_conditions, local_authority_district, local_authority_highway, local_authority_ons_district, location_easting_osgr, location_northing_osgr, longitude, lsoa_of_accident_location, lsoa_of_collision_location, number_of_casualties, number_of_vehicles, pedestrian_crossing_human_control, pedestrian_crossing_physical_facilities, police_force, road_surface_conditions, road_type, second_road_class, second_road_number, special_conditions_at_site, speed_limit, time, trunk_road_flag, urban_or_rural_area, weather_conditions, age_band_of_casualty, age_of_casualty, bus_or_coach_passenger, car_passenger, casualty_class, casualty_distance_banding, casualty_home_area_type, casualty_imd_decile, casualty_reference, casualty_severity, casualty_type, enhanced_casualty_severity, lsoa_of_casualty, pedestrian_location, pedestrian_movement, pedestrian_road_maintenance_worker, sex_of_casualty, adjusted_serious, adjusted_slight, injury_based, accident_ref_no, effective_date_of_change, previously_published_value, replacement_value, variable\nNAs introduced by coercion\nNAs introduced by coercion\nThe three objects read-in above correspond to the main types of entity that are recorded by the police:\nEach table represents the same phenomena: road casualties in Great Britain in 2023. Therefore, you may expect they would have the same number of rows, but this is not the case:\nnrow(ac)\n\n[1] 104258\n\nnrow(ca)\n\n[1] 132977\n\nnrow(ve)\n\n[1] 189815\nThe reason for this is that there are, on average, more than one casualty per crash (e.g. when a car hits two people), and more than one vehicle, including bicycles, per crash. We can find the average number of casualties and vehicles per crash as follows:\nnrow(ca) / nrow(ac)\n\n[1] 1.275461\n\nnrow(ve) / nrow(ac)\n\n[1] 1.820628\nThe output of the commands above show that there are around 1.3 casualties and 1.8 vehicles involved in each crash record in the STATS19 dataset for 2023. Each table contains a different number of columns, reporting the characteristics of each casualty and each driver/vehicle for the ca and ve datasets respectively.\nncol(ac)\n\n[1] 38\n\nncol(ca)\n\n[1] 21\n\nncol(ve)\n\n[1] 34\nThe output of the previous code chunk shows that we have more variables in the ‘accidents’ table than the others but the others, but the other tables are data rich with 16 columns on the casualties and 23 on the vehicles. To check that the datasets are consistent, we can check that the number of casualties reported in the crashes table is equal to the number of rows in the casualties table, and the same for the vehicles table:\nac$number_of_casualties = as.numeric(ac$number_of_casualties)\nac$number_of_vehicles = as.numeric(ac$number_of_vehicles)\nsum(ac$number_of_casualties) == nrow(ca) \n\n[1] TRUE\n\nsum(ac$number_of_vehicles) == nrow(ve)   \n\n[1] TRUE",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Joining road crash tables</span>"
    ]
  },
  {
    "objectID": "08-join.html#stats19-tables",
    "href": "08-join.html#stats19-tables",
    "title": "8  Joining road crash tables",
    "section": "",
    "text": "Crashes: The ‘crash event’ table contains general data about crashes, including where and when they happened and the conditions in which the crash occurred (e.g. light levels in the column light_conditions in the ac object). For historical reasons, crash level data is stored in tables called ‘Accidents’ (a term that has fallen out of favour because it implies that nobody was at fault). See names for all 33 variables in the crashes table by running the command names(ac). Crashes range from collisions involving only one vehicle and another entity (e.g. a person on foot, bicycle or a car) causing only ‘slight’ injuries such as a graze, to multi-vehicle pile-ups involving multiple deaths and dozens of slight and serious injuries.\nCasualties: The casualties table, assigned to an object called ca in the code above, contains data at the casualty level. As you will see by running the command names(ca), the STATS19 casualties table has 16 variables including age_of_casualty, casualty_severity and casualty_type, reporting the mode of transport in which the person was travelling when they were hit.\nVehicles: The vehicles table, assigned to ve above, contains information about the vehicles and their drivers involved in each collision. As you will see by running the command names(ve), the 23 variables in this table includes vehicle_type, hit_object_off_carriageway and first_point_of_impact. Information about the driver of vehicles involved is contained in variables such as age_of_driver, engine_capacity_cc and age_of_vehicle.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Joining road crash tables</span>"
    ]
  },
  {
    "objectID": "08-join.html#joining-casualty-data",
    "href": "08-join.html#joining-casualty-data",
    "title": "8  Joining road crash tables",
    "section": "8.2 Joining casualty data",
    "text": "8.2 Joining casualty data\nTo join casualty (or vehicle) data onto the ac object above, the inner_join() function from dplyr can be used as follows:\n\nac_cas_joined = inner_join(ac, ca)\n\nJoining with `by = join_by(accident_index, accident_year, accident_reference)`\n\n\nThe above command worked because the two datasets have a shared variable name: accident_index. Note that the command worked by duplicating accident records for multiple casualties. We can see this finding the accident that had the most crashes and printing the results in the ac and new joined dataset, as follows:\n\nid_with_most_crashes = ac %&gt;% \n  top_n(n = 1, wt = number_of_casualties) %&gt;% \n  pull(accident_index)\nid_with_most_crashes\n\n[1] \"2023520300610\"\n\nac %&gt;% filter(accident_index == id_with_most_crashes) %&gt;% \n  select(accident_index, accident_severity, number_of_vehicles, number_of_casualties)\n\n# A tibble: 1 × 4\n  accident_index accident_severity number_of_vehicles number_of_casualties\n  &lt;chr&gt;          &lt;chr&gt;                          &lt;dbl&gt;                &lt;dbl&gt;\n1 2023520300610  Serious                            3                   70\n\nac_cas_joined %&gt;% filter(accident_index == id_with_most_crashes) %&gt;% \n  select(accident_index, accident_severity, number_of_vehicles, number_of_casualties, casualty_reference)\n\n# A tibble: 70 × 5\n   accident_index accident_severity number_of_vehicles number_of_casualties\n   &lt;chr&gt;          &lt;chr&gt;                          &lt;dbl&gt;                &lt;dbl&gt;\n 1 2023520300610  Serious                            3                   70\n 2 2023520300610  Serious                            3                   70\n 3 2023520300610  Serious                            3                   70\n 4 2023520300610  Serious                            3                   70\n 5 2023520300610  Serious                            3                   70\n 6 2023520300610  Serious                            3                   70\n 7 2023520300610  Serious                            3                   70\n 8 2023520300610  Serious                            3                   70\n 9 2023520300610  Serious                            3                   70\n10 2023520300610  Serious                            3                   70\n# ℹ 60 more rows\n# ℹ 1 more variable: casualty_reference &lt;chr&gt;",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Joining road crash tables</span>"
    ]
  },
  {
    "objectID": "08-join.html#joining-vehicle-data",
    "href": "08-join.html#joining-vehicle-data",
    "title": "8  Joining road crash tables",
    "section": "8.3 Joining vehicle data",
    "text": "8.3 Joining vehicle data\nThe same approach can be used to join vehicle data onto the crash record data:\n\nac_veh_joined = inner_join(ac, ve)\n\nJoining with `by = join_by(accident_index, accident_year, accident_reference)`\n\n\nThis information can be used as the basis of who-hit-who visualisation, in this case looking at vehicles involved in the most common type of casualties (recoded using the trafficalmr package):\n\nremotes::install_github(\"saferactive/trafficalmr\")\nlibrary(trafficalmr)\nac_cas_joined$cas_type = tc_recode_casualties(ac_cas_joined$casualty_type)\np = c(`HGV_occupant|Minibus_occupant|Taxi_occupant|Moto*.+` = \"Other\")\nac_cas_joined$cas_type = tc_recode_casualties(ac_cas_joined$cas_type, pattern = p)\nbarplot(table(ac_cas_joined$cas_type))\n\n\n\n\nBarplot of recoded casualty type frequencies\n\n\n\n\nTo find the largest vehicle involved in each casualty, we can similarly pre-process the vehicle data as follows:\n\np = c(`Van*.+` = \"Van\", `Pedal cycle` = \"Bicycle\",\n  `(M|m)otorcycle*.+|Elec*.+` = \"Motorcycle\",\n  `Taxi*|Data*.+|Agri*.+|Ridden*.+|Mobility*.+|Tram*.+|(M|m)otorcycle*.+|Elec*.+` = \"Other\",\n  `Bus*.+` = \"Bus\", `Bus|Minibus*.+|Other*.+` = \"Other\", `Goods*.+` = \"HGV\")\nac_veh_joined$veh_type = tc_recode_vehicle_type(ac_veh_joined$vehicle_type, p)\nl = c(\"Bicycle\", \"Car\", \"Other\", \"Van\", \"HGV\")\nac_veh_joined$vehicle = factor(ac_veh_joined$veh_type, levels = l, ordered = TRUE)\nsummary(ac_veh_joined$vehicle)\n\nBicycle     Car   Other     Van     HGV    NA's \n  15667  130164   28006   11727    4225      26 \n\nac_veh_largest = ac_veh_joined %&gt;% \n  group_by(accident_index) %&gt;% \n  summarise(largest_vehicle = max(vehicle))\n\n\nac_cas_veh_largest = inner_join(ac_cas_joined, ac_veh_largest) \n\nJoining with `by = join_by(accident_index)`\n\ncas_veh_table = table(ac_cas_veh_largest$cas_type, ac_cas_veh_largest$largest_vehicle)\ncvt_df = as.data.frame(cas_veh_table)\nggplot(cvt_df) +\n  geom_bar(aes(Var2, Freq, fill = Var1), stat = \"identity\") +\n  scale_fill_discrete(\"Casualty type\") +\n  xlab(\"Largest vehicle involved\") +\n  ylab(\"Number of casualties\")\n\n\n\n\n\n\n\nFigure 8.1: ‘Who hit who’ visualisation of number of casualties (y axis) hurt in crashes involving different vehicle types (largest vehicle in each crash on Y axis).",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Joining road crash tables</span>"
    ]
  },
  {
    "objectID": "08-join.html#case-study-london",
    "href": "08-join.html#case-study-london",
    "title": "8  Joining road crash tables",
    "section": "8.4 Case study: London",
    "text": "8.4 Case study: London\nThe three main tables we have just read-in can be joined by the accident_index variable and then filtered using other variables. This is demonstrated in the code chunk below, which subsets all casualties that took place in London, and counts the number of casualties by severity for each crash:\n\nlibrary(tidyr)\nlibrary(dplyr)\nac_sf = format_sf(ac)\nlnd_police = c(\"City of London\", \"Metropolitan Police\")\nac_lnd = ac_sf %&gt;% \n  filter(police_force %in% lnd_police)\nca_lnd = ca %&gt;% \n  filter(accident_index %in% ac_lnd$accident_index)\ncas_types = ca_lnd %&gt;% \n  select(accident_index, casualty_type) %&gt;% \n  group_by(accident_index) %&gt;% \n  summarise(\n    Total = n(),\n    walking = sum(casualty_type == \"Pedestrian\"),\n    cycling = sum(casualty_type == \"Cyclist\"),\n    passenger = sum(casualty_type == \"Car occupant\")\n    ) \ncj = left_join(ac_lnd, cas_types)\n\nWhat just happened? We found the subset of casualties that took place in London with reference to the accident_index variable. Then we used the dplyr function, summarise(), to find the number of people who were in a car, cycling, and walking when they were injured. This new casualty dataset is joined onto the crashes_lnd dataset. The result is a spatial (sf) data frame of ac in London, with columns counting how many road users of different types were hurt. The joined data has additional variables:\n\nbase::setdiff(names(cj), names(ac_lnd))\n\n[1] \"Total\"     \"walking\"   \"cycling\"   \"passenger\"\n\n\nAs a simple spatial plot, we can map all crashes that occurred in London in 2023, with the colour related to the total number of people hurt in each crash. Placing this plot next to a map of London provides context:\ncj$speed_limit = as.numeric(cj$speed_limit)\nplot(\n  cj[cj$cycling &gt; 0, \"speed_limit\", ],\n  cex = cj$Total[cj$cycling &gt; 0] / 3,\n  main = \"Speed limit (cycling)\"\n  )\nplot(\n  cj[cj$passenger &gt; 0, \"speed_limit\", ],\n  cex = cj$Total[cj$passenger &gt; 0] / 3,\n  main = \"Speed limit (passenger)\"\n  )\n\n\n\n\n\n\n\n\n\n\nThe spatial distribution of crashes in London clearly relates to the region’s geography. Car crashes tend to happen on fast roads, including busy dual carriageway roads, displayed in yellow in Figure 8.2 above. Cycling is as an urban activity, and the most bike crashes can be found in or near the centre of London, which has a comparatively high level of cycling (compared to the low baseline of 3%).\nIn addition to the Total number of people hurt/killed, cj contains a column for each type of casualty (cyclist, car occupant, etc.), and a number corresponding to casualties in crashes involving each type of vehicle. It also contains the geometry column from ac_sf. In other words, joins allow the casualties and vehicles tables to be geo-referenced. We can then explore the spatial distribution of different casualty types. For example, Figure 8.3 shows the spatial distribution of pedestrians and car passengers hurt in car crashes across London in 2023, via the following code:\n\nlibrary(ggplot2)\nac_types = cj %&gt;% \n  filter(accident_severity != \"Slight\") %&gt;% \n  mutate(type = case_when(\n    walking &gt; 0 ~ \"Walking\",\n    cycling &gt; 0 ~ \"Cycling\",\n    passenger &gt; 0 ~ \"Passenger\",\n    TRUE ~ \"Other\"\n  ))\nac_types$speed_limit = as.numeric(ac_types$speed_limit)\nggplot(ac_types, aes(size = Total, colour = speed_limit)) +\n  geom_sf(show.legend = \"point\", alpha = 0.3) +\n  facet_grid(vars(type), vars(accident_severity)) +\n  scale_size(\n    breaks = c(1:3, 12),\n    labels = c(1:2, \"3+\", 12)\n    ) +\n  scale_color_gradientn(colours = c(\"blue\", \"yellow\", \"red\")) +\n  theme(axis.text = element_blank(), axis.ticks = element_blank())\n\n\n\n\n\n\n\nFigure 8.2: Spatial distribution of serious and fatal crashes in London, for cycling, walking, being a car passenger and other modes of travel. Colour is related to the speed limit where the crash happened (red is faster) and size is proportional to the total number of people hurt in each crash (legend not shown).\n\n\n\n\n\nExercises:\n\nThere is a lot going on in the code in this chapter, the most advanced of the guide. With reference to online help, work through the code line-by-line and look-up any aspects of the code that you do not fully understand to help figure out what is going on.\nReproduce the final figures for a different city of your choice (not London).\nBonus: Create more attractive interactive maps to show the spatial distribution of different casualty types in the city of your choice.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Joining road crash tables</span>"
    ]
  },
  {
    "objectID": "09-next.html",
    "href": "09-next.html",
    "title": "9  Next steps",
    "section": "",
    "text": "9.1 Automated reporting with RMarkdown\nYou have reached the end of this short guide on reproducible road safety research with R. Armed with the knowledge of what R and RStudio can do, and how add-on packages provide powerful tools for a wide range of data analysis, visualisation and statistical modelling tasks, you should have a much better understanding of the language’s capabilities.\nI hope that in the process of working through the exercises, you have learned not only the technicalities of data science with a powerful tool of the trade, but also a way of working that puts reproducibility centre stage. Learning any new skill takes time and effort. However, in my experience, once you get past a critical threshold, the amount of time saved using the new approach starts to outweigh the amount of time involved in becoming fluent. The same concept applies to other ‘tools of the trade’ that are available, such as the open source geographic information system (GIS) software, QGIS and other languages for data science, such as Python and Julia.\nRather than go off and learn such additional tools, we encourage you to stick with R. It is preferable to know one language in-depth and then branch out to learn other approaches than to learn many approaches superficially or, as put it in the excellent R for Data Science (R4DS) book: “You will get better faster if you dive deep, rather than spreading yourself thinly over many topics”. In terms of next steps, you cannot go wrong with checking-out the R4DS website which, like this book, has worked examples and exercises in abundance on a much wider range of data science topics. As you will see by visiting r4ds.had.co.nz many of these topics, including workflow and modelling, will be of use from a road safety research perspective.\nA strength of R is its flexibility. It can be used as a calculator one minute and a statistical modelling toolbox the next. R can be used as a web application development framework the next, as illustrated by major shiny apps such as the Propensity to Cycle Tool (try it at www.pct.bike) and tools developed by road safety consultancy Agilysis, described in Section 9.1 below. Indeed, within the R ecosystem there are many sub-ecosystems, each of which has excellence free and open resources for people who want to learn more in a particular domain. If you are particularly in the geographic analysis of road crash data, the book Geocomputation with R by yours truly and which has already been mentioned in Chapter 7, is highly recommended. If you are looking for methods of analysing trends and forecasting with time series data, is highly recommended. Indeed, there is a whole library’s worth of open resources to be found on any area of data-driven research online, from web development and visualisation to text analysis. A recommended next step for learning more in regards to any of these areas is the website bookdown.org, which links to books that can also be bought as physical items if you, like many people, prefer learning with a paper resource.\nIn fact, with the size and rapidly evolving nature of the R ecosystem, one of the hardest things for a beginner is knowing which packages, functions or workflow options to choose from out of a wide array of options. The internet is there to help you, but it can also hinder your progress by serving-up out-of-date solutions and providing ‘quick fixes’ at the expense of a deep understanding. Therefore, instead of trying to be comprehensive (focussed web searches prioritising tried-and-tested solutions documented in authoritative sources can help with that), the rest of this final section provides pointers on a few particularly useful aspects of R from a road safety analysis perspective. Most people who learn R (or any computer language) will at become frustrated due to tricky-to-fix error messages. As outlined in Section 9.1, written by people who have navigated R’s at first daunting learning curve, it can take only a few weeks of learning to get to the point where saves more time than it consumes and takes your work “to the next level”.\nAn advantage of R is that it has many packages dedicated to the communication and publication of results, vital for policy impact. Perhaps the most important important package with regards to the communication of results is rmarkdown. This is more of a framework than a package, providing a powerful system for generating reports, web pages and even books (this book was written with the bookdown package, which builds onrmarkdown).\nHere is not the place to explain how to use RMarkdown and their associated .Rmd files. The framework is explained in detail in a free and open book. To get started with the framework, however, you can try the following code example, which shows the creation of an Rmd file:\nfile.edit(\"test-document.Rmd\")\nTry adding some code chunks and text by following the guidance in the Rmd cheatsheet, which you can get from the Help &gt; Cheatsheets menu in RStudio.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Next steps</span>"
    ]
  },
  {
    "objectID": "09-next.html#sharing-code",
    "href": "09-next.html#sharing-code",
    "title": "9  Next steps",
    "section": "9.2 Sharing code",
    "text": "9.2 Sharing code\nAnother way to increase the impact of your code is to share it. This can help collaborate with colleagues, getting feedback from others, and generating interest in your work as part of collaborative research processes that have been in operation for hundreds of years, as summarised by the phrase, ‘Building on the shoulders of giants.’ A more prosaic, but perhaps more important, corollary to that is, ‘Do not reinvent the wheel.’ By getting your code ‘out there’ you will be able to ensure that others can use your code and, because publishing your code encourages searching for other code bases, help you to find components written by others to improve your work. Sharing code can therefore save many hours of time, provided you are happy to read and re-use, and of course give due credit and reference to code and ideas from other people.\nThe easiest way to share code in 2023 (and likely for the foreseeable future) is GitHub, an online code sharing, project management and file hosting platform. A great way to get started with GitHub, after you have signed up and created a user name at github.com, is to contribute to an existing project. Challenge: suggest a change to the code repository on GitHub that contains the source code of this book.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Next steps</span>"
    ]
  },
  {
    "objectID": "09-next.html#asking-questions",
    "href": "09-next.html#asking-questions",
    "title": "9  Next steps",
    "section": "9.3 Asking questions",
    "text": "9.3 Asking questions\nA final thing to say on R before the testimonials below is how to ask questions. There are many places to ask for help online, including:\n\nThe question and answer site https://stackoverflow.com/. You will get quick answers here but be warned, answers may not always be particularly friendly if you ask a question that doesn’t make sense or which has already been answered in the documentation - that should not put you off though, sometimes it’s a case of, ‘Don’t ask, don’t get.’\nThe https://community.rstudio.com/ forum, where you may get more detailed and friendlier responses, especially if the question relates to RStudio, although the answer may be slower.\nSpecial interest groups such as https://gis.stackexchange.com/ (for GIS related questions), and the Slack group RSGB Analyst Network for road safety data analysis questions\n\nPerhaps better than all of the above, is to ask a colleague who has slightly more experience than you. That way you will build ‘collaboration networks.’ The final thing to say on asking questions is ‘use reprex!’ To see what I mean by this try typing the following:\n\n# example of creating a good reprex:\nreprex::reprex({\n  x = 1\n  y = \"2\"\n  # why does this fail?\n  x + y\n  # but this succeeds?\n  x + as.numeric(y)\n})\n# after running the code above you can share the copied output to help ask questions\n\nNote, you can turn any bit of code into a ‘reprex’ by selecting it and by running the ‘Reprex selection’ addin in RStudio, as described on the Tidyverse website.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Next steps</span>"
    ]
  },
  {
    "objectID": "09-next.html#testimonials",
    "href": "09-next.html#testimonials",
    "title": "9  Next steps",
    "section": "9.4 Testimonials",
    "text": "9.4 Testimonials\nThis final section provides insight not only into how R can be used for road safety research from a range of perspectives, but also navigating R’s at times steep learning curve.\n\n9.4.1 R for professional road safety analysts\nWill Cubbin, Road Safety Strategy Analyst, Safer Essex Roads Partnership\nWhen I attended the two-day course ‘introduction to R’ I had little confidence in my natural ability to learn coding. Although familiar with many functions in Excel and having dabbled in VBA, my two previous attempts at any kind of computer language both ended in literal failure. At university I failed a module on C++ and in a previous job I failed a training course on SQL!\nAs expected the course was a steep learning curve but after two days I had definitely learned a few tricks. However I was still concerned about the amount of material covered by the course that I hadn’t understood. It turned out this was actually a good thing because the breadth of the course showed me what R was capable of, and how it could be useful. The next part of my journey with R was to use the course materials and build on the basics I had learned, to achieve what the course showed was possible.\nI began with the aim of using the geospatial analysis capability in R to visualise collision data in new ways, to give more detailed insight and present it in a way that would inform meaningful action for front line resources. Having a clear goal of “This is what I want to achieve with my first R project” was crucial. The course had given me an idea of the sort of processes I needed to undertake in order to achieve this goal. The post-course support through GitHub was very good, I also learned a lot by finding examples of code on places like GitHub and stackoverflow through Google searches. The other crucial element in getting my first success with R was having time dedicated to working on the project immediately after the course. I spent two weeks working almost exclusively on this project, starting the week after the R course.\nThe result was well worth the effort. After the initial two weeks of intensive learning with R, I spent 4 to 6 weeks working on the project a couple of days per week. By the end of this period I had working versions of two interactive mapping tools, comprising: 1) A multi layered leaflet map showing collision locations, collision density along main roads and a “heatmap” (Kernel Density Estimation raster) layer. I made multiple versions of each layer for different modes of transport and behaviours such as drink driving. 2) A ‘shiny’ mapping app showing collision locations and basic details with date filter. I was able to embed this on our website for public use. It can be viewed here SERP website data page under the heading ‘Interactive Map’.\nI soon added a second R script to the first of the two projects described above. This script produced and exported a range of standardised infographics showing various breakdowns of the data contained in the map. This allowed me to almost fully-automate the process for updating a proactive Roads-Policing tasking document. It turned this monthly process, which previously took 1 working day to complete, into one taking just 45 minutes. It also added more useful insight to the monthly tasking product.\nMy next steps are to continue another project using an API to access vehicle telematics data. This project extracts driving events, such as harsh braking and harsh cornering, and plots them on an interactive map. I will also be using R for some statistical analysis as part of a research project I have recently started. Thinking of myself as an “Excel native”, I would say R hasn’t replaced Excel, but has been a powerful addition to my toolbox so I can do more interesting and in-depth work than ever before.\n\n\n9.4.2 R in a road safety research consultancy\nDr Craig Smith, Data Scientist, Agilysis Ltd\nAfter attending my first R course, I immediately saw how useful the language could be to our team. At Agilysis, we have integrated R into almost everything our analytics team does, pushing for our work to be as robust and reproducible as possible. The incredible integration R has with SQL database engines, cloud-based infrastructure like AWS, and proprietary GIS software like ArcGIS, has given us a huge scope to automate a lot of our regular data processing tasks. The added ability to automate the production of reports, charts and maps has allowed us to gain quick insights into our data, speeding up our exploratory analysis. The huge Shiny ecosystem has allowed us to produce interactive applications for sharing our tools and visualisations with stakeholders. There is also a wide range of open-source statistical and machine learning packages available which, when combined with the added capability to translate and use tools from python, has allowed us to innovate and take full advantage of what artificial intelligence has to offer. All of this, embedded in a supportive community of R users that is continually sharing its knowledge and helping spread these skills, means that anything is possible for users, whatever their level of experience. The fact that this community includes a growing number of road safety analysts and transport-focused data scientists (thanks, in part, to this book and the previous R for Road Safety courses) means that there are plenty of like-minded R users all over the country that you can share ideas (and code) with.\n\n\n9.4.3 Using R in a road safety charity\nEmily Nagler, Data Analyst, RAC Foundation\nI was first introduced to R in my master’s program by a professor who was very enthusiastic as to how much better it was than ArcGIS for spatial analysis. Whilst he did project his views very strongly on us as students, I still tended towards ArcGIS when given a choice between the two. I had never written code before this point, and to me the GUI of ArcGIS was simply easier to work with. However, over the course of my program I incorporated R more and more as our coursework became increasingly complex. Datasets with tens of thousands of rows quickly became a pain in Excel, and the inefficiency of working between two programs rather than one was tedious. Like many of my classmates, I soon realised the point our professor had been trying to make all along: in order to push your analytical capabilities to the next level you need to use the right tool. I can agree that there is a steep learning curve to R, but once you’ve become comfortable with the language, it’s harder to go back than it is to go forward. Meaning, once you reach a point in your proficiency, it’s easier to build on your skills and knowledge of the language than it is to revert back to Excel knowing there is a smarter alternative.\nI found myself face to face with R again in my role at the RAC Foundation a year later, and since I’d already become an R convert, it was easy to pick up again. However, now I saw new benefits from a different perspective, relating to collaboration and reproducibility. Before this point, the only eyes on my scripts were my own, and there was no need to refer back to them once an assignment was done. However, in my role as a data analyst, it is important and necessary to create something that can be shared and understood by others. The ability to have a full account written out line by line makes it much easier to work off someone else’s code and, importantly, to quality check one another’s work. By having a traceable, repeatable analysis, there is a level of accountability with the method that you simply cannot get in Excel.\nAnother great aspect of R is the helpful online community presence, thanks to its open source nature. Anyone can access the software, and anyone can contribute to the discussion, which I often find more helpful than the FAQs of a paid for software. I would say that this aspect alone has helped hugely in my work, both academically and professionally. I’m never far from an answer when stuck, no matter how specific the problem gets. In terms of its use in my work on road safety and transport analysis it has become a great tool for combining data with maps, something that I think highlights results in a more insightful way. That being said, visualisation is just as important as the analysis, and I’ve been pleased with the array of packages that can create eye-catching maps, interactive dashboards, and much more outside of the traditional data wrangling capabilities. Looking to the future of my career I see myself continuing to use R and I’m confident that its capabilities will only get better the more people engage with it.\n\n\n9.4.4 Using R in other areas of road safety research\nDo you have a use case of reproducible research? Please get in touch on the issue tracker.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Next steps</span>"
    ]
  }
]